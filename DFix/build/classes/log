1 css loaded
1 css loaded
Add signal to org/apache/cassandra/service/StorageService handleStateNormal 604
Fetch StorageService from the CUTABLE
~~~ add semaphore to StorageService
        calculatePendingRanges(1);
->         calculatePendingRanges(1); DFix_Signal();

1 occurence use replace instead of replacefirst
    get CU to replace for BootStrapper
            tokenString = ss.getBootstrapToken().toString();
-> tokenString = DFix_Wait();
1 occurence use replace instead of replacefirst
setting rpc to org/apache/cassandra/service/StorageService initServer 362
    get AnSString to replace for StorageService
            token = BootStrapper.getBootstrapToken(tokenMetadata_, StorageLoadBalancer.instance.getLoadInfo());
-> token = DFix_Socket();

1 occurence use replace instead of replacefirst
RPC repeat added
--------  PATCH DETAILS  ---------

In the BootStrapper.java

---              tokenString = ss.getBootstrapToken().toString();
+++  tokenString = DFix_Wait();

In the StorageService.java

+++    public Semaphore se_dfix = new Semaphore(0);

---          calculatePendingRanges(1);
+++          calculatePendingRanges(1); DFix_Signal();


---              token = BootStrapper.getBootstrapToken(tokenMetadata_, StorageLoadBalancer.instance.getLoadInfo());
+++  token = DFix_Socket();


In the BootStrapper.java

DFix_Wait():
try { 
if (StorageService.se_dfix.tryAcquire(1,5,java.util.concurrent.TimeUnit.SECONDS) ) 
            tokenString = ss.getBootstrapToken().toString();
else tokenString ="00000000000000000000000";
} catch (InterruptedException e_dfix) {
}
 return tokenString;


In the StorageService.java

DFix_Signal():
se_dfix.release(1);


DFix_Socket():
  while (true) {
            token = BootStrapper.getBootstrapToken(tokenMetadata_, StorageLoadBalancer.instance.getLoadInfo());
if (!token.toString().equals("0"))
break;}
return token;


2 css loaded
2 css loaded
Cloning org/apache/hadoop/yarn/state/StateMachineFactory$InternalStateMachine doTransition 443 -> StateMachineFactory$InternalStateMachine
Fetch StateMachineFactory$InternalStateMachine from the CUTABLE
Clone functionorg/apache/hadoop/yarn/state/StateMachineFactory$InternalStateMachine doTransition 443
Cloning org/apache/hadoop/yarn/state/StateMachineFactory$InternalStateMachine doTransition 443 -> StateMachineFactory$InternalStateMachine
Fetch StateMachineFactory$InternalStateMachine from the CUTABLE
Fetch StateMachineFactory from the CUTABLE
    get CU to replace for MRClientService
      appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL));
->       appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL)); DFix_EventWait();
1 occurence use replace instead of replacefirst
Set the EE-Site wait to org/apache/hadoop/mapreduce/v2/app/client/MRClientService$MRClientProtocolHandler killTaskAttempt 323
Add signal to org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl handle 926
Fetch TaskAttemptImpl from the CUTABLE
~~~ add semaphore to TaskAttemptImpl
        stateMachine.doTransition(event.getType(), event);
->         stateMachine.doTransition(event.getType(), event); DFix_Signal();

1 occurence use replace instead of replacefirst
Extend the unchange prove to an upper layer
    get AnSString to replace for TaskAttemptImpl
        stateMachine.doTransition(event.getType(), event);
-> DFix_EventWait(event);

1 occurence use replace instead of replacefirst
setting rpc to org/apache/hadoop/mapred/ClientServiceDelegate invoke 289
    get CU to replace for ClientServiceDelegate
        return methodOb.invoke(dfix_proxy, args);
-> return DFix_Rpc();
1 occurence use replace instead of replacefirst
RPC repeat added
    get AnSString to replace for TaskAttemptImpl
NOT found ???  what's wrong???
        stateMachine.doTransition(event.getType(), event); 
/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/
package org.apache.hadoop.mapreduce.v2.app.job.impl;

import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Collection;
import java.util.EnumSet;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;
import java.util.regex.Pattern;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DataOutputBuffer;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.MapReduceChildJVM;
import org.apache.hadoop.mapred.ShuffleHandler;
import org.apache.hadoop.mapred.Task;
import org.apache.hadoop.mapred.TaskAttemptContextImpl;
import org.apache.hadoop.mapred.WrappedJvmID;
import org.apache.hadoop.mapred.WrappedProgressSplitsBlock;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Counters;
import org.apache.hadoop.mapreduce.JobCounter;
import org.apache.hadoop.mapreduce.MRJobConfig;
import org.apache.hadoop.mapreduce.OutputCommitter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.TaskCounter;
import org.apache.hadoop.mapreduce.TypeConverter;
import org.apache.hadoop.mapreduce.jobhistory.JobHistoryEvent;
import org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent;
import org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent;
import org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent;
import org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent;
import org.apache.hadoop.mapreduce.security.TokenCache;
import org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier;
import org.apache.hadoop.mapreduce.v2.api.records.Phase;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptReport;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskType;
import org.apache.hadoop.mapreduce.v2.app.TaskAttemptListener;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobCounterUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobDiagnosticsUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobTaskAttemptFetchFailureEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptContainerAssignedEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptContainerLaunchedEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptDiagnosticsUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent.TaskAttemptStatus;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskTAttemptEvent;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent;
import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator;
import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocatorEvent;
import org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent;
import org.apache.hadoop.mapreduce.v2.app.speculate.SpeculatorEvent;
import org.apache.hadoop.mapreduce.v2.app.taskclean.TaskCleanupEvent;
import org.apache.hadoop.mapreduce.v2.util.MRApps;
import org.apache.hadoop.net.NetUtils;
import org.apache.hadoop.security.Credentials;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.security.token.Token;
import org.apache.hadoop.security.token.TokenIdentifier;
import org.apache.hadoop.util.StringUtils;
import org.apache.hadoop.yarn.Clock;
import org.apache.hadoop.yarn.YarnException;
import org.apache.hadoop.yarn.api.ApplicationConstants.Environment;
import org.apache.hadoop.yarn.api.records.ApplicationAccessType;
import org.apache.hadoop.yarn.api.records.ContainerId;
import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
import org.apache.hadoop.yarn.api.records.ContainerToken;
import org.apache.hadoop.yarn.api.records.LocalResource;
import org.apache.hadoop.yarn.api.records.LocalResourceType;
import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
import org.apache.hadoop.yarn.api.records.NodeId;
import org.apache.hadoop.yarn.api.records.Resource;
import org.apache.hadoop.yarn.api.records.URL;
import org.apache.hadoop.yarn.event.EventHandler;
import org.apache.hadoop.yarn.factories.RecordFactory;
import org.apache.hadoop.yarn.factory.providers.RecordFactoryProvider;
import org.apache.hadoop.yarn.state.InvalidStateTransitonException;
import org.apache.hadoop.yarn.state.SingleArcTransition;
import org.apache.hadoop.yarn.state.StateMachine;
import org.apache.hadoop.yarn.state.StateMachineFactory;
import org.apache.hadoop.yarn.util.Apps;
import org.apache.hadoop.yarn.util.BuilderUtils;
import org.apache.hadoop.yarn.util.ConverterUtils;
import org.apache.hadoop.yarn.util.RackResolver;
import java.util.concurrent.Semaphore;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Implementation of TaskAttempt interface.
 */
@SuppressWarnings({ "rawtypes" })
public abstract class TaskAttemptImpl implements org.apache.hadoop.mapreduce.v2.app.job.TaskAttempt, EventHandler<TaskAttemptEvent> {

    static final Counters EMPTY_COUNTERS = new Counters();

    private static final Log LOG = LogFactory.getLog(TaskAttemptImpl.class);

    //TODO Make configurable?
    private static final long MEMORY_SPLITS_RESOLUTION = 1024;

    private static final int MAP_MEMORY_MB_DEFAULT = 1024;

    private static final int REDUCE_MEMORY_MB_DEFAULT = 1024;

    private static final RecordFactory recordFactory = RecordFactoryProvider.getRecordFactory(null);

    protected final JobConf conf;

    protected final Path jobFile;

    protected final int partition;

    protected EventHandler eventHandler;

    private final TaskAttemptId attemptId;

    private final Clock clock;

    private final org.apache.hadoop.mapred.JobID oldJobId;

    private final TaskAttemptListener taskAttemptListener;

    private final OutputCommitter committer;

    private final Resource resourceCapability;

    private final String[] dataLocalHosts;

    private final List<String> diagnostics = new ArrayList<String>();

    private final Lock readLock;

    private final Lock writeLock;

    private Collection<Token<? extends TokenIdentifier>> fsTokens;

    private Token<JobTokenIdentifier> jobToken;

    private static AtomicBoolean initialClasspathFlag = new AtomicBoolean();

    private static String initialClasspath = null;

    private static Object commonContainerSpecLock = new Object();

    private static ContainerLaunchContext commonContainerSpec = null;

    private static final Object classpathLock = new Object();

    private long launchTime;

    private long finishTime;

    private WrappedProgressSplitsBlock progressSplitBlock;

    private int shufflePort = -1;

    private String trackerName;

    private int httpPort;

    private static final CleanupContainerTransition CLEANUP_CONTAINER_TRANSITION = new CleanupContainerTransition();

    private static final DiagnosticInformationUpdater DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION = new DiagnosticInformationUpdater();

    private static final StateMachineFactory<TaskAttemptImpl, TaskAttemptState, TaskAttemptEventType, TaskAttemptEvent> stateMachineFactory = new StateMachineFactory<TaskAttemptImpl, TaskAttemptState, TaskAttemptEventType, TaskAttemptEvent>(TaskAttemptState.NEW).addTransition(TaskAttemptState.NEW, TaskAttemptState.UNASSIGNED, TaskAttemptEventType.TA_SCHEDULE, new RequestContainerTransition(false)).addTransition(TaskAttemptState.NEW, TaskAttemptState.UNASSIGNED, TaskAttemptEventType.TA_RESCHEDULE, new RequestContainerTransition(true)).addTransition(TaskAttemptState.NEW, TaskAttemptState.KILLED, TaskAttemptEventType.TA_KILL, new KilledTransition()).addTransition(TaskAttemptState.NEW, TaskAttemptState.FAILED, TaskAttemptEventType.TA_FAILMSG, new FailedTransition()).addTransition(TaskAttemptState.UNASSIGNED, TaskAttemptState.ASSIGNED, TaskAttemptEventType.TA_ASSIGNED, new ContainerAssignedTransition()).addTransition(TaskAttemptState.UNASSIGNED, TaskAttemptState.KILLED, TaskAttemptEventType.TA_KILL, new DeallocateContainerTransition(TaskAttemptState.KILLED, true)).addTransition(TaskAttemptState.UNASSIGNED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_FAILMSG, new DeallocateContainerTransition(TaskAttemptState.FAILED, true)).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.RUNNING, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, new LaunchedContainerTransition()).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.ASSIGNED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_CONTAINER_LAUNCH_FAILED, new DeallocateContainerTransition(TaskAttemptState.FAILED, false)).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_CONTAINER_COMPLETED, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_KILL, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_FAILMSG, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.RUNNING, TaskAttemptEventType.TA_UPDATE, new StatusUpdater()).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.RUNNING, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DONE, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.COMMIT_PENDING, TaskAttemptEventType.TA_COMMIT_PENDING, new CommitPendingTransition()).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_FAILMSG, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_CONTAINER_COMPLETED, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_TIMED_OUT, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_KILL, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.COMMIT_PENDING, TaskAttemptEventType.TA_UPDATE, new StatusUpdater()).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.COMMIT_PENDING, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DONE, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_KILL, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_FAILMSG, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_CONTAINER_COMPLETED, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_TIMED_OUT, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptState.SUCCEEDED, TaskAttemptEventType.TA_CONTAINER_CLEANED, new SucceededTransition()).addTransition(TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_TIMED_OUT, TaskAttemptEventType.TA_CONTAINER_COMPLETED)).addTransition(TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptEventType.TA_CONTAINER_CLEANED, new TaskCleanupTransition()).addTransition(TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptState.FAIL_CONTAINER_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_TIMED_OUT)).addTransition(TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptEventType.TA_CONTAINER_CLEANED, new TaskCleanupTransition()).addTransition(TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptState.KILL_CONTAINER_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_TIMED_OUT)).addTransition(TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptState.FAILED, TaskAttemptEventType.TA_CLEANUP_DONE, new FailedTransition()).addTransition(TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptState.FAIL_TASK_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).addTransition(TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptState.KILLED, TaskAttemptEventType.TA_CLEANUP_DONE, new KilledTransition()).addTransition(TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptState.KILL_TASK_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).addTransition(//only possible for map attempts
    TaskAttemptState.SUCCEEDED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE, new TooManyFetchFailureTransition()).addTransition(TaskAttemptState.SUCCEEDED, TaskAttemptState.SUCCEEDED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.SUCCEEDED, TaskAttemptState.SUCCEEDED, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_CONTAINER_COMPLETED)).addTransition(TaskAttemptState.FAILED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.FAILED, TaskAttemptState.FAILED, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_ASSIGNED, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).addTransition(TaskAttemptState.KILLED, TaskAttemptState.KILLED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.KILLED, TaskAttemptState.KILLED, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_ASSIGNED, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).installTopology();

    private final StateMachine<TaskAttemptState, TaskAttemptEventType, TaskAttemptEvent> stateMachine;

    private ContainerId containerID;

    private NodeId containerNodeId;

    private String containerMgrAddress;

    private String nodeHttpAddress;

    private String nodeRackName;

    private WrappedJvmID jvmID;

    private ContainerToken containerToken;

    private Resource assignedCapability;

    //this takes good amount of memory ~ 30KB. Instantiate it lazily
    //and make it null once task is launched.
    private org.apache.hadoop.mapred.Task remoteTask;

    //this is the last status reported by the REMOTE running attempt
    private TaskAttemptStatus reportedStatus;

    private static final String LINE_SEPARATOR = System.getProperty("line.separator");

    public TaskAttemptImpl(TaskId taskId, int i, EventHandler eventHandler, TaskAttemptListener taskAttemptListener, Path jobFile, int partition, JobConf conf, String[] dataLocalHosts, OutputCommitter committer, Token<JobTokenIdentifier> jobToken, Collection<Token<? extends TokenIdentifier>> fsTokens, Clock clock) {
        oldJobId = TypeConverter.fromYarn(taskId.getJobId());
        this.conf = conf;
        this.clock = clock;
        attemptId = recordFactory.newRecordInstance(TaskAttemptId.class);
        attemptId.setTaskId(taskId);
        attemptId.setId(i);
        this.taskAttemptListener = taskAttemptListener;
        // Initialize reportedStatus
        reportedStatus = new TaskAttemptStatus();
        initTaskAttemptStatus(reportedStatus);
        ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
        readLock = readWriteLock.readLock();
        writeLock = readWriteLock.writeLock();
        this.fsTokens = fsTokens;
        this.jobToken = jobToken;
        this.eventHandler = eventHandler;
        this.committer = committer;
        this.jobFile = jobFile;
        this.partition = partition;
        //TODO:create the resource reqt for this Task attempt
        this.resourceCapability = recordFactory.newRecordInstance(Resource.class);
        this.resourceCapability.setMemory(getMemoryRequired(conf, taskId.getTaskType()));
        this.dataLocalHosts = dataLocalHosts;
        RackResolver.init(conf);
        // This "this leak" is okay because the retained pointer is in an
        //  instance variable.
        stateMachine = stateMachineFactory.make(this);
    }

    private int getMemoryRequired(Configuration conf, TaskType taskType) {
        int memory = 1024;
        if (taskType == TaskType.MAP) {
            memory = conf.getInt(MRJobConfig.MAP_MEMORY_MB, MAP_MEMORY_MB_DEFAULT);
        } else if (taskType == TaskType.REDUCE) {
            memory = conf.getInt(MRJobConfig.REDUCE_MEMORY_MB, REDUCE_MEMORY_MB_DEFAULT);
        }
        return memory;
    }

    /**
   * Create a {@link LocalResource} record with all the given parameters.
   */
    private static LocalResource createLocalResource(FileSystem fc, Path file, LocalResourceType type, LocalResourceVisibility visibility) throws IOException {
        FileStatus fstat = fc.getFileStatus(file);
        URL resourceURL = ConverterUtils.getYarnUrlFromPath(fc.resolvePath(fstat.getPath()));
        long resourceSize = fstat.getLen();
        long resourceModificationTime = fstat.getModificationTime();
        return BuilderUtils.newLocalResource(resourceURL, type, visibility, resourceSize, resourceModificationTime);
    }

    /**
   * Lock this on initialClasspath so that there is only one fork in the AM for
   * getting the initial class-path. TODO: We already construct
   * a parent CLC and use it for all the containers, so this should go away
   * once the mr-generated-classpath stuff is gone.
   */
    private static String getInitialClasspath(Configuration conf) throws IOException {
        synchronized (classpathLock) {
            if (initialClasspathFlag.get()) {
                return initialClasspath;
            }
            Map<String, String> env = new HashMap<String, String>();
            MRApps.setClasspath(env, conf);
            initialClasspath = env.get(Environment.CLASSPATH.name());
            initialClasspathFlag.set(true);
            return initialClasspath;
        }
    }

    /**
   * Create the common {@link ContainerLaunchContext} for all attempts.
   * @param applicationACLs 
   */
    private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Collection<Token<? extends TokenIdentifier>> fsTokens) {
        // Application resources
        Map<String, LocalResource> localResources = new HashMap<String, LocalResource>();
        // Application environment
        Map<String, String> environment = new HashMap<String, String>();
        // Service data
        Map<String, ByteBuffer> serviceData = new HashMap<String, ByteBuffer>();
        // Tokens
        ByteBuffer tokens = ByteBuffer.wrap(new byte[] {});
        try {
            FileSystem remoteFS = FileSystem.get(conf);
            // //////////// Set up JobJar to be localized properly on the remote NM.
            String jobJar = conf.get(MRJobConfig.JAR);
            if (jobJar != null) {
                Path remoteJobJar = (new Path(jobJar)).makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory());
                localResources.put(MRJobConfig.JOB_JAR, createLocalResource(remoteFS, remoteJobJar, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION));
                LOG.info("The job-jar file on the remote FS is " + remoteJobJar.toUri().toASCIIString());
            } else {
                // Job jar may be null. For e.g, for pipes, the job jar is the hadoop
                // mapreduce jar itself which is already on the classpath.
                LOG.info("Job jar is not present. " + "Not adding any jar to the list of resources.");
            }
            // //////////// End of JobJar setup
            // //////////// Set up JobConf to be localized properly on the remote NM.
            Path path = MRApps.getStagingAreaDir(conf, UserGroupInformation.getCurrentUser().getShortUserName());
            Path remoteJobSubmitDir = new Path(path, oldJobId.toString());
            Path remoteJobConfPath = new Path(remoteJobSubmitDir, MRJobConfig.JOB_CONF_FILE);
            localResources.put(MRJobConfig.JOB_CONF_FILE, createLocalResource(remoteFS, remoteJobConfPath, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION));
            LOG.info("The job-conf file on the remote FS is " + remoteJobConfPath.toUri().toASCIIString());
            // //////////// End of JobConf setup
            // Setup DistributedCache
            MRApps.setupDistributedCache(conf, localResources);
            // Setup up tokens
            Credentials taskCredentials = new Credentials();
            if (UserGroupInformation.isSecurityEnabled()) {
                // Add file-system tokens
                for (Token<? extends TokenIdentifier> token : fsTokens) {
                    LOG.info("Putting fs-token for NM use for launching container : " + token.toString());
                    taskCredentials.addToken(token.getService(), token);
                }
            }
            // LocalStorageToken is needed irrespective of whether security is enabled
            // or not.
            TokenCache.setJobToken(jobToken, taskCredentials);
            DataOutputBuffer containerTokens_dob = new DataOutputBuffer();
            LOG.info("Size of containertokens_dob is " + taskCredentials.numberOfTokens());
            taskCredentials.writeTokenStorageToStream(containerTokens_dob);
            tokens = ByteBuffer.wrap(containerTokens_dob.getData(), 0, containerTokens_dob.getLength());
            // Add shuffle token
            LOG.info("Putting shuffle token in serviceData");
            serviceData.put(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID, ShuffleHandler.serializeServiceData(jobToken));
            Apps.addToEnvironment(environment, Environment.CLASSPATH.name(), getInitialClasspath(conf));
        } catch (IOException e) {
            throw new YarnException(e);
        }
        // Shell
        environment.put(Environment.SHELL.name(), conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL, MRJobConfig.DEFAULT_SHELL));
        // Add pwd to LD_LIBRARY_PATH, add this before adding anything else
        Apps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(), Environment.PWD.$());
        // Add the env variables passed by the admin
        Apps.setEnvFromInputString(environment, conf.get(MRJobConfig.MAPRED_ADMIN_USER_ENV, MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV));
        // Construct the actual Container
        // The null fields are per-container and will be constructed for each
        // container separately.
        ContainerLaunchContext container = BuilderUtils.newContainerLaunchContext(null, conf.get(MRJobConfig.USER_NAME), null, localResources, environment, null, serviceData, tokens, applicationACLs);
        return container;
    }

    static ContainerLaunchContext createContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, ContainerId containerID, Configuration conf, Token<JobTokenIdentifier> jobToken, Task remoteTask, final org.apache.hadoop.mapred.JobID oldJobId, Resource assignedCapability, WrappedJvmID jvmID, TaskAttemptListener taskAttemptListener, Collection<Token<? extends TokenIdentifier>> fsTokens) {
        synchronized (commonContainerSpecLock) {
            if (commonContainerSpec == null) {
                commonContainerSpec = createCommonContainerLaunchContext(applicationACLs, conf, jobToken, oldJobId, fsTokens);
            }
        }
        // Fill in the fields needed per-container that are missing in the common
        // spec.
        // Setup environment by cloning from common env.
        Map<String, String> env = commonContainerSpec.getEnvironment();
        Map<String, String> myEnv = new HashMap<String, String>(env.size());
        myEnv.putAll(env);
        MapReduceChildJVM.setVMEnv(myEnv, remoteTask);
        // Set up the launch command
        List<String> commands = MapReduceChildJVM.getVMCommand(taskAttemptListener.getAddress(), remoteTask, jvmID);
        // Duplicate the ByteBuffers for access by multiple containers.
        Map<String, ByteBuffer> myServiceData = new HashMap<String, ByteBuffer>();
        for (Entry<String, ByteBuffer> entry : commonContainerSpec.getServiceData().entrySet()) {
            myServiceData.put(entry.getKey(), entry.getValue().duplicate());
        }
        // Construct the actual Container
        ContainerLaunchContext container = BuilderUtils.newContainerLaunchContext(containerID, commonContainerSpec.getUser(), assignedCapability, commonContainerSpec.getLocalResources(), myEnv, commands, myServiceData, commonContainerSpec.getContainerTokens().duplicate(), applicationACLs);
        return container;
    }

    @Override
    public ContainerId getAssignedContainerID() {
        readLock.lock();
        try {
            return containerID;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public String getAssignedContainerMgrAddress() {
        readLock.lock();
        try {
            return containerMgrAddress;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getLaunchTime() {
        readLock.lock();
        try {
            return launchTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getFinishTime() {
        readLock.lock();
        try {
            return finishTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getShuffleFinishTime() {
        readLock.lock();
        try {
            return this.reportedStatus.shuffleFinishTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getSortFinishTime() {
        readLock.lock();
        try {
            return this.reportedStatus.sortFinishTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public int getShufflePort() {
        readLock.lock();
        try {
            return shufflePort;
        } finally {
            readLock.unlock();
        }
    }

    /**If container Assigned then return the node's address, otherwise null.
   */
    @Override
    public String getNodeHttpAddress() {
        readLock.lock();
        try {
            return nodeHttpAddress;
        } finally {
            readLock.unlock();
        }
    }

    /**
   * If container Assigned then return the node's rackname, otherwise null.
   */
    @Override
    public String getNodeRackName() {
        this.readLock.lock();
        try {
            return this.nodeRackName;
        } finally {
            this.readLock.unlock();
        }
    }

    protected abstract org.apache.hadoop.mapred.Task createRemoteTask();

    @Override
    public TaskAttemptId getID() {
        return attemptId;
    }

    @Override
    public boolean isFinished() {
        readLock.lock();
        try {
            // TODO: Use stateMachine level method?
            return (getState() == TaskAttemptState.SUCCEEDED || getState() == TaskAttemptState.FAILED || getState() == TaskAttemptState.KILLED);
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public TaskAttemptReport getReport() {
        TaskAttemptReport result = recordFactory.newRecordInstance(TaskAttemptReport.class);
        readLock.lock();
        try {
            result.setTaskAttemptId(attemptId);
            //take the LOCAL state of attempt
            //DO NOT take from reportedStatus
            result.setTaskAttemptState(getState());
            result.setProgress(reportedStatus.progress);
            result.setStartTime(launchTime);
            result.setFinishTime(finishTime);
            result.setShuffleFinishTime(this.reportedStatus.shuffleFinishTime);
            result.setDiagnosticInfo(StringUtils.join(LINE_SEPARATOR, getDiagnostics()));
            result.setPhase(reportedStatus.phase);
            result.setStateString(reportedStatus.stateString);
            result.setCounters(TypeConverter.toYarn(getCounters()));
            result.setContainerId(this.getAssignedContainerID());
            result.setNodeManagerHost(trackerName);
            result.setNodeManagerHttpPort(httpPort);
            if (this.containerNodeId != null) {
                result.setNodeManagerPort(this.containerNodeId.getPort());
            }
            return result;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public List<String> getDiagnostics() {
        List<String> result = new ArrayList<String>();
        readLock.lock();
        try {
            result.addAll(diagnostics);
            return result;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public Counters getCounters() {
        readLock.lock();
        try {
            Counters counters = reportedStatus.counters;
            if (counters == null) {
                counters = EMPTY_COUNTERS;
            //        counters.groups = new HashMap<String, CounterGroup>();
            }
            return counters;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public float getProgress() {
        readLock.lock();
        try {
            return reportedStatus.progress;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public TaskAttemptState getState() {
        readLock.lock();
        try {
            return stateMachine.getCurrentState();
        } finally {
            readLock.unlock();
        }
    }

    @SuppressWarnings("unchecked")
    @Override
    public void handle(TaskAttemptEvent event) {
        if (LOG.isDebugEnabled()) {
            LOG.debug("Processing " + event.getTaskAttemptID() + " of type " + event.getType());
        }
        writeLock.lock();
        try {
            final TaskAttemptState oldState = getState();
            try {
        DFix_EventWait(event);
 DFix_Signal();

            } catch (InvalidStateTransitonException e) {
                //        if (event.getType().toString().equals("TA_DIAGNOSTICS_UPDATE")){
                //            eventHandler.handle(event);
                //	      try {Thread.sleep(900);} catch (Exception _e){}
                //            LOG.info("DIG event is reput to the queue ------- ");
                //            writeLock.unlock();
                //	    return;
                //        }
                LOG.info(event.getType());
                LOG.error("Can't handle this event at current state for " + this.attemptId, e);
                eventHandler.handle(new JobDiagnosticsUpdateEvent(this.attemptId.getTaskId().getJobId(), "Invalid event " + event.getType() + " on TaskAttempt " + this.attemptId));
                eventHandler.handle(new JobEvent(this.attemptId.getTaskId().getJobId(), JobEventType.INTERNAL_ERROR));
            }
            if (oldState != getState()) {
                LOG.info(attemptId + " TaskAttempt Transitioned from " + oldState + " to " + getState());
            }
        } finally {
            writeLock.unlock();
        }
    }

    //always called in write lock
    private void setFinishTime() {
        //set the finish time only if launch time is set
        if (launchTime != 0) {
            finishTime = clock.getTime();
        }
    }

    private static long computeSlotMillis(TaskAttemptImpl taskAttempt) {
        TaskType taskType = taskAttempt.getID().getTaskId().getTaskType();
        int slotMemoryReq = taskAttempt.getMemoryRequired(taskAttempt.conf, taskType);
        int simSlotsRequired = slotMemoryReq / (taskType == TaskType.MAP ? MAP_MEMORY_MB_DEFAULT : REDUCE_MEMORY_MB_DEFAULT);
        // Simulating MRv1 slots for counters by assuming *_MEMORY_MB_DEFAULT
        // corresponds to a MrV1 slot.
        // Fallow slot millis is not applicable in MRv2 - since a container is
        // either assigned with the required memory or is not. No partial
        // reserveations
        long slotMillisIncrement = simSlotsRequired * (taskAttempt.getFinishTime() - taskAttempt.getLaunchTime());
        return slotMillisIncrement;
    }

    private static JobCounterUpdateEvent createJobCounterUpdateEventTAFailed(TaskAttemptImpl taskAttempt) {
        TaskType taskType = taskAttempt.getID().getTaskId().getTaskType();
        JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskAttempt.getID().getTaskId().getJobId());
        long slotMillisIncrement = computeSlotMillis(taskAttempt);
        if (taskType == TaskType.MAP) {
            jce.addCounterUpdate(JobCounter.NUM_FAILED_MAPS, 1);
            jce.addCounterUpdate(JobCounter.SLOTS_MILLIS_MAPS, slotMillisIncrement);
        } else {
            jce.addCounterUpdate(JobCounter.NUM_FAILED_REDUCES, 1);
            jce.addCounterUpdate(JobCounter.SLOTS_MILLIS_REDUCES, slotMillisIncrement);
        }
        return jce;
    }

    private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {
        TaskAttemptUnsuccessfulCompletionEvent tauce = new TaskAttemptUnsuccessfulCompletionEvent(TypeConverter.fromYarn(taskAttempt.attemptId), TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()), attemptState.toString(), taskAttempt.finishTime, taskAttempt.containerNodeId == null ? "UNKNOWN" : taskAttempt.containerNodeId.getHost(), taskAttempt.containerNodeId == null ? -1 : taskAttempt.containerNodeId.getPort(), taskAttempt.nodeRackName == null ? "UNKNOWN" : taskAttempt.nodeRackName, StringUtils.join(LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt.getProgressSplitBlock().burst());
        return tauce;
    }

    private WrappedProgressSplitsBlock getProgressSplitBlock() {
        readLock.lock();
        try {
            if (progressSplitBlock == null) {
                progressSplitBlock = new WrappedProgressSplitsBlock(conf.getInt(MRJobConfig.MR_AM_NUM_PROGRESS_SPLITS, MRJobConfig.DEFAULT_MR_AM_NUM_PROGRESS_SPLITS));
            }
            return progressSplitBlock;
        } finally {
            readLock.unlock();
        }
    }

    private void updateProgressSplits() {
        double newProgress = reportedStatus.progress;
        Counters counters = reportedStatus.counters;
        if (counters == null)
            return;
        WrappedProgressSplitsBlock splitsBlock = getProgressSplitBlock();
        if (splitsBlock != null) {
            long now = clock.getTime();
            // TODO Ensure not 0
            long start = getLaunchTime();
            if (start != 0 && now - start <= Integer.MAX_VALUE) {
                splitsBlock.getProgressWallclockTime().extend(newProgress, (int) (now - start));
            }
            Counter cpuCounter = counters.findCounter(TaskCounter.CPU_MILLISECONDS);
            if (cpuCounter != null && cpuCounter.getValue() <= Integer.MAX_VALUE) {
                splitsBlock.getProgressCPUTime().extend(newProgress, // long to int? TODO: FIX. Same below
                (int) cpuCounter.getValue());
            }
            Counter virtualBytes = counters.findCounter(TaskCounter.VIRTUAL_MEMORY_BYTES);
            if (virtualBytes != null) {
                splitsBlock.getProgressVirtualMemoryKbytes().extend(newProgress, (int) (virtualBytes.getValue() / (MEMORY_SPLITS_RESOLUTION)));
            }
            Counter physicalBytes = counters.findCounter(TaskCounter.PHYSICAL_MEMORY_BYTES);
            if (physicalBytes != null) {
                splitsBlock.getProgressPhysicalMemoryKbytes().extend(newProgress, (int) (physicalBytes.getValue() / (MEMORY_SPLITS_RESOLUTION)));
            }
        }
    }

    static class RequestContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        private final boolean rescheduled;

        public RequestContainerTransition(boolean rescheduled) {
            this.rescheduled = rescheduled;
        }

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // Tell any speculator that we're requesting a container
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.getID().getTaskId(), +1));
            //request for container
            if (rescheduled) {
                taskAttempt.eventHandler.handle(ContainerRequestEvent.createContainerRequestEventForFailedContainer(taskAttempt.attemptId, taskAttempt.resourceCapability));
            } else {
                Set<String> racks = new HashSet<String>();
                for (String host : taskAttempt.dataLocalHosts) {
                    racks.add(RackResolver.resolve(host).getNetworkLocation());
                }
                taskAttempt.eventHandler.handle(new ContainerRequestEvent(taskAttempt.attemptId, taskAttempt.resourceCapability, taskAttempt.resolveHosts(taskAttempt.dataLocalHosts), racks.toArray(new String[racks.size()])));
            }
        }
    }

    protected String[] resolveHosts(String[] src) {
        String[] result = new String[src.length];
        for (int i = 0; i < src.length; i++) {
            if (isIP(src[i])) {
                result[i] = resolveHost(src[i]);
            } else {
                result[i] = src[i];
            }
        }
        return result;
    }

    protected String resolveHost(String src) {
        // Fallback in case of failure.
        String result = src;
        try {
            InetAddress addr = InetAddress.getByName(src);
            result = addr.getHostName();
        } catch (UnknownHostException e) {
            LOG.warn("Failed to resolve address: " + src + ". Continuing to use the same.");
        }
        return result;
    }

    private static final // Pattern for matching ip
    Pattern ipPattern = Pattern.compile("\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}");

    protected boolean isIP(String src) {
        return ipPattern.matcher(src).matches();
    }

    private static class ContainerAssignedTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings({ "unchecked" })
        @Override
        public void transition(final TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            final TaskAttemptContainerAssignedEvent cEvent = (TaskAttemptContainerAssignedEvent) event;
            taskAttempt.containerID = cEvent.getContainer().getId();
            taskAttempt.containerNodeId = cEvent.getContainer().getNodeId();
            taskAttempt.containerMgrAddress = taskAttempt.containerNodeId.toString();
            taskAttempt.nodeHttpAddress = cEvent.getContainer().getNodeHttpAddress();
            taskAttempt.nodeRackName = RackResolver.resolve(taskAttempt.containerNodeId.getHost()).getNetworkLocation();
            taskAttempt.containerToken = cEvent.getContainer().getContainerToken();
            taskAttempt.assignedCapability = cEvent.getContainer().getResource();
            // this is a _real_ Task (classic Hadoop mapred flavor):
            taskAttempt.remoteTask = taskAttempt.createRemoteTask();
            taskAttempt.jvmID = new WrappedJvmID(taskAttempt.remoteTask.getTaskID().getJobID(), taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());
            taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.remoteTask, taskAttempt.jvmID);
            //launch the container
            //create the container object to be launched for a given Task attempt
            ContainerLaunchContext launchContext = createContainerLaunchContext(cEvent.getApplicationACLs(), taskAttempt.containerID, taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.assignedCapability, taskAttempt.jvmID, taskAttempt.taskAttemptListener, taskAttempt.fsTokens);
            taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(taskAttempt.attemptId, taskAttempt.containerID, taskAttempt.containerMgrAddress, taskAttempt.containerToken, launchContext, taskAttempt.remoteTask));
            // send event to speculator that our container needs are satisfied
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));
        }
    }

    private static class DeallocateContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        private final TaskAttemptState finalState;

        private final boolean withdrawsContainerRequest;

        DeallocateContainerTransition(TaskAttemptState finalState, boolean withdrawsContainerRequest) {
            this.finalState = finalState;
            this.withdrawsContainerRequest = withdrawsContainerRequest;
        }

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //set the finish time
            taskAttempt.setFinishTime();
            //send the deallocate event to ContainerAllocator
            taskAttempt.eventHandler.handle(new ContainerAllocatorEvent(taskAttempt.attemptId, ContainerAllocator.EventType.CONTAINER_DEALLOCATE));
            //  we're transitioning out of UNASSIGNED
            if (withdrawsContainerRequest) {
                taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));
            }
            switch(finalState) {
                case FAILED:
                    taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_FAILED));
                    break;
                case KILLED:
                    taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_KILLED));
                    break;
            }
            if (taskAttempt.getLaunchTime() != 0) {
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, finalState);
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
        }
    }

    private static class LaunchedContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent evnt) {
            TaskAttemptContainerLaunchedEvent event = (TaskAttemptContainerLaunchedEvent) evnt;
            //set the launch time
            taskAttempt.launchTime = taskAttempt.clock.getTime();
            taskAttempt.shufflePort = event.getShufflePort();
            // register it to TaskAttemptListener so that it can start monitoring it.
            taskAttempt.taskAttemptListener.registerLaunchedTask(taskAttempt.attemptId, taskAttempt.jvmID);
            //TODO Resolve to host / IP in case of a local address.
            InetSocketAddress nodeHttpInetAddr = // TODO:
            NetUtils.createSocketAddr(taskAttempt.nodeHttpAddress);
            // Costly?
            taskAttempt.trackerName = nodeHttpInetAddr.getHostName();
            taskAttempt.httpPort = nodeHttpInetAddr.getPort();
            JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskAttempt.attemptId.getTaskId().getJobId());
            jce.addCounterUpdate(taskAttempt.attemptId.getTaskId().getTaskType() == TaskType.MAP ? JobCounter.TOTAL_LAUNCHED_MAPS : JobCounter.TOTAL_LAUNCHED_REDUCES, 1);
            taskAttempt.eventHandler.handle(jce);
            LOG.info("TaskAttempt: [" + taskAttempt.attemptId + "] using containerId: [" + taskAttempt.containerID + " on NM: [" + taskAttempt.containerMgrAddress + "]");
            TaskAttemptStartedEvent tase = new TaskAttemptStartedEvent(TypeConverter.fromYarn(taskAttempt.attemptId), TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()), taskAttempt.launchTime, nodeHttpInetAddr.getHostName(), nodeHttpInetAddr.getPort(), taskAttempt.shufflePort, taskAttempt.containerID);
            taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tase));
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.attemptId, true, taskAttempt.clock.getTime()));
            //make remoteTask reference as null as it is no more needed
            //and free up the memory
            taskAttempt.remoteTask = null;
            //tell the Task that attempt has started
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_LAUNCHED));
        }
    }

    private static class CommitPendingTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_COMMIT_PENDING));
        }
    }

    private static class TaskCleanupTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            TaskAttemptContext taskContext = new TaskAttemptContextImpl(taskAttempt.conf, TypeConverter.fromYarn(taskAttempt.attemptId));
            taskAttempt.eventHandler.handle(new TaskCleanupEvent(taskAttempt.attemptId, taskAttempt.committer, taskContext));
        }
    }

    private static class SucceededTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //set the finish time
            taskAttempt.setFinishTime();
            long slotMillis = computeSlotMillis(taskAttempt);
            TaskId taskId = taskAttempt.attemptId.getTaskId();
            JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskId.getJobId());
            jce.addCounterUpdate(taskId.getTaskType() == TaskType.MAP ? JobCounter.SLOTS_MILLIS_MAPS : JobCounter.SLOTS_MILLIS_REDUCES, slotMillis);
            taskAttempt.eventHandler.handle(jce);
            taskAttempt.logAttemptFinishedEvent(TaskAttemptState.SUCCEEDED);
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_SUCCEEDED));
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.reportedStatus, taskAttempt.clock.getTime()));
        }
    }

    private static class FailedTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // set the finish time
            taskAttempt.setFinishTime();
            if (taskAttempt.getLaunchTime() != 0) {
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, TaskAttemptState.FAILED);
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            // taskAttempt.logAttemptFinishedEvent(TaskAttemptState.FAILED); Not
            // handling failed map/reduce events.
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_FAILED));
        }
    }

    @SuppressWarnings({ "unchecked" })
    private void logAttemptFinishedEvent(TaskAttemptState state) {
        //Log finished events only if an attempt started.
        if (getLaunchTime() == 0)
            return;
        if (attemptId.getTaskId().getTaskType() == TaskType.MAP) {
            MapAttemptFinishedEvent mfe = new MapAttemptFinishedEvent(TypeConverter.fromYarn(attemptId), TypeConverter.fromYarn(attemptId.getTaskId().getTaskType()), state.toString(), this.reportedStatus.mapFinishTime, finishTime, this.containerNodeId == null ? "UNKNOWN" : this.containerNodeId.getHost(), this.containerNodeId == null ? -1 : this.containerNodeId.getPort(), this.nodeRackName == null ? "UNKNOWN" : this.nodeRackName, this.reportedStatus.stateString, getCounters(), getProgressSplitBlock().burst());
            eventHandler.handle(new JobHistoryEvent(attemptId.getTaskId().getJobId(), mfe));
        } else {
            ReduceAttemptFinishedEvent rfe = new ReduceAttemptFinishedEvent(TypeConverter.fromYarn(attemptId), TypeConverter.fromYarn(attemptId.getTaskId().getTaskType()), state.toString(), this.reportedStatus.shuffleFinishTime, this.reportedStatus.sortFinishTime, finishTime, this.containerNodeId == null ? "UNKNOWN" : this.containerNodeId.getHost(), this.containerNodeId == null ? -1 : this.containerNodeId.getPort(), this.nodeRackName == null ? "UNKNOWN" : this.nodeRackName, this.reportedStatus.stateString, getCounters(), getProgressSplitBlock().burst());
            eventHandler.handle(new JobHistoryEvent(attemptId.getTaskId().getJobId(), rfe));
        }
    }

    private static class TooManyFetchFailureTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //add to diagnostic
            taskAttempt.addDiagnosticInfo("Too Many fetch failures.Failing the attempt");
            //set the finish time
            taskAttempt.setFinishTime();
            if (taskAttempt.getLaunchTime() != 0) {
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, TaskAttemptState.FAILED);
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_FAILED));
        }
    }

    private static class KilledTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //set the finish time
            taskAttempt.setFinishTime();
            if (taskAttempt.getLaunchTime() != 0) {
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, TaskAttemptState.KILLED);
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
            //      taskAttempt.logAttemptFinishedEvent(TaskAttemptState.KILLED); Not logging Map/Reduce attempts in case of failure.
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_KILLED));
        }
    }

    private static class CleanupContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // unregister it to TaskAttemptListener so that it stops listening
            // for it
            taskAttempt.taskAttemptListener.unregister(taskAttempt.attemptId, taskAttempt.jvmID);
            taskAttempt.reportedStatus.progress = 1.0f;
            taskAttempt.updateProgressSplits();
            //send the cleanup event to containerLauncher
            taskAttempt.eventHandler.handle(new ContainerLauncherEvent(taskAttempt.attemptId, taskAttempt.containerID, taskAttempt.containerMgrAddress, taskAttempt.containerToken, ContainerLauncher.EventType.CONTAINER_REMOTE_CLEANUP));
        }
    }

    private void addDiagnosticInfo(String diag) {
        if (diag != null && !diag.equals("")) {
            diagnostics.add(diag);
        }
    }

    private static class StatusUpdater implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // Status update calls don't really change the state of the attempt.
            TaskAttemptStatus newReportedStatus = ((TaskAttemptStatusUpdateEvent) event).getReportedTaskAttemptStatus();
            // Now switch the information in the reportedStatus
            taskAttempt.reportedStatus = newReportedStatus;
            taskAttempt.reportedStatus.taskState = taskAttempt.getState();
            // send event to speculator about the reported status
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.reportedStatus, taskAttempt.clock.getTime()));
            taskAttempt.updateProgressSplits();
            //this only will happen in reduce attempt type
            if (taskAttempt.reportedStatus.fetchFailedMaps != null && taskAttempt.reportedStatus.fetchFailedMaps.size() > 0) {
                taskAttempt.eventHandler.handle(new JobTaskAttemptFetchFailureEvent(taskAttempt.attemptId, taskAttempt.reportedStatus.fetchFailedMaps));
            }
        }
    }

    private static class DiagnosticInformationUpdater implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            TaskAttemptDiagnosticsUpdateEvent diagEvent = (TaskAttemptDiagnosticsUpdateEvent) event;
            LOG.info("Diagnostics report from " + taskAttempt.attemptId + ": " + diagEvent.getDiagnosticInfo());
            taskAttempt.addDiagnosticInfo(diagEvent.getDiagnosticInfo());
        }
    }

    private void initTaskAttemptStatus(TaskAttemptStatus result) {
        result.progress = 0.0f;
        result.phase = Phase.STARTING;
        result.stateString = "NEW";
        result.taskState = TaskAttemptState.NEW;
        Counters counters = EMPTY_COUNTERS;
        //    counters.groups = new HashMap<String, CounterGroup>();
        result.counters = counters;
    }

    public Semaphore se_dfix = new Semaphore(0);
}

        stateMachine.doTransition(event.getType(), event);
-> if (event.getType().equals("TA_ASSIGNED"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);
0 occurence use replace instead of replacefirst
No change:
ADD CLONE : ---          stateMachine.doTransition(event.getType(), event);
+++  if (event.getType().equals("TA_ASSIGNED"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);
set clone call org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl handle 926
    get AnSString to replace for TaskAttemptImpl
NOT found ???  what's wrong???
        stateMachine.doTransition(event.getType(), event); 
/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/
package org.apache.hadoop.mapreduce.v2.app.job.impl;

import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Collection;
import java.util.EnumSet;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;
import java.util.regex.Pattern;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DataOutputBuffer;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.MapReduceChildJVM;
import org.apache.hadoop.mapred.ShuffleHandler;
import org.apache.hadoop.mapred.Task;
import org.apache.hadoop.mapred.TaskAttemptContextImpl;
import org.apache.hadoop.mapred.WrappedJvmID;
import org.apache.hadoop.mapred.WrappedProgressSplitsBlock;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Counters;
import org.apache.hadoop.mapreduce.JobCounter;
import org.apache.hadoop.mapreduce.MRJobConfig;
import org.apache.hadoop.mapreduce.OutputCommitter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.TaskCounter;
import org.apache.hadoop.mapreduce.TypeConverter;
import org.apache.hadoop.mapreduce.jobhistory.JobHistoryEvent;
import org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent;
import org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent;
import org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent;
import org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent;
import org.apache.hadoop.mapreduce.security.TokenCache;
import org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier;
import org.apache.hadoop.mapreduce.v2.api.records.Phase;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptReport;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskType;
import org.apache.hadoop.mapreduce.v2.app.TaskAttemptListener;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobCounterUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobDiagnosticsUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobTaskAttemptFetchFailureEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptContainerAssignedEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptContainerLaunchedEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptDiagnosticsUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent.TaskAttemptStatus;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskTAttemptEvent;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent;
import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator;
import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocatorEvent;
import org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent;
import org.apache.hadoop.mapreduce.v2.app.speculate.SpeculatorEvent;
import org.apache.hadoop.mapreduce.v2.app.taskclean.TaskCleanupEvent;
import org.apache.hadoop.mapreduce.v2.util.MRApps;
import org.apache.hadoop.net.NetUtils;
import org.apache.hadoop.security.Credentials;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.security.token.Token;
import org.apache.hadoop.security.token.TokenIdentifier;
import org.apache.hadoop.util.StringUtils;
import org.apache.hadoop.yarn.Clock;
import org.apache.hadoop.yarn.YarnException;
import org.apache.hadoop.yarn.api.ApplicationConstants.Environment;
import org.apache.hadoop.yarn.api.records.ApplicationAccessType;
import org.apache.hadoop.yarn.api.records.ContainerId;
import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
import org.apache.hadoop.yarn.api.records.ContainerToken;
import org.apache.hadoop.yarn.api.records.LocalResource;
import org.apache.hadoop.yarn.api.records.LocalResourceType;
import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
import org.apache.hadoop.yarn.api.records.NodeId;
import org.apache.hadoop.yarn.api.records.Resource;
import org.apache.hadoop.yarn.api.records.URL;
import org.apache.hadoop.yarn.event.EventHandler;
import org.apache.hadoop.yarn.factories.RecordFactory;
import org.apache.hadoop.yarn.factory.providers.RecordFactoryProvider;
import org.apache.hadoop.yarn.state.InvalidStateTransitonException;
import org.apache.hadoop.yarn.state.SingleArcTransition;
import org.apache.hadoop.yarn.state.StateMachine;
import org.apache.hadoop.yarn.state.StateMachineFactory;
import org.apache.hadoop.yarn.util.Apps;
import org.apache.hadoop.yarn.util.BuilderUtils;
import org.apache.hadoop.yarn.util.ConverterUtils;
import org.apache.hadoop.yarn.util.RackResolver;
import java.util.concurrent.Semaphore;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Implementation of TaskAttempt interface.
 */
@SuppressWarnings({ "rawtypes" })
public abstract class TaskAttemptImpl implements org.apache.hadoop.mapreduce.v2.app.job.TaskAttempt, EventHandler<TaskAttemptEvent> {

    static final Counters EMPTY_COUNTERS = new Counters();

    private static final Log LOG = LogFactory.getLog(TaskAttemptImpl.class);

    //TODO Make configurable?
    private static final long MEMORY_SPLITS_RESOLUTION = 1024;

    private static final int MAP_MEMORY_MB_DEFAULT = 1024;

    private static final int REDUCE_MEMORY_MB_DEFAULT = 1024;

    private static final RecordFactory recordFactory = RecordFactoryProvider.getRecordFactory(null);

    protected final JobConf conf;

    protected final Path jobFile;

    protected final int partition;

    protected EventHandler eventHandler;

    private final TaskAttemptId attemptId;

    private final Clock clock;

    private final org.apache.hadoop.mapred.JobID oldJobId;

    private final TaskAttemptListener taskAttemptListener;

    private final OutputCommitter committer;

    private final Resource resourceCapability;

    private final String[] dataLocalHosts;

    private final List<String> diagnostics = new ArrayList<String>();

    private final Lock readLock;

    private final Lock writeLock;

    private Collection<Token<? extends TokenIdentifier>> fsTokens;

    private Token<JobTokenIdentifier> jobToken;

    private static AtomicBoolean initialClasspathFlag = new AtomicBoolean();

    private static String initialClasspath = null;

    private static Object commonContainerSpecLock = new Object();

    private static ContainerLaunchContext commonContainerSpec = null;

    private static final Object classpathLock = new Object();

    private long launchTime;

    private long finishTime;

    private WrappedProgressSplitsBlock progressSplitBlock;

    private int shufflePort = -1;

    private String trackerName;

    private int httpPort;

    private static final CleanupContainerTransition CLEANUP_CONTAINER_TRANSITION = new CleanupContainerTransition();

    private static final DiagnosticInformationUpdater DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION = new DiagnosticInformationUpdater();

    private static final StateMachineFactory<TaskAttemptImpl, TaskAttemptState, TaskAttemptEventType, TaskAttemptEvent> stateMachineFactory = new StateMachineFactory<TaskAttemptImpl, TaskAttemptState, TaskAttemptEventType, TaskAttemptEvent>(TaskAttemptState.NEW).addTransition(TaskAttemptState.NEW, TaskAttemptState.UNASSIGNED, TaskAttemptEventType.TA_SCHEDULE, new RequestContainerTransition(false)).addTransition(TaskAttemptState.NEW, TaskAttemptState.UNASSIGNED, TaskAttemptEventType.TA_RESCHEDULE, new RequestContainerTransition(true)).addTransition(TaskAttemptState.NEW, TaskAttemptState.KILLED, TaskAttemptEventType.TA_KILL, new KilledTransition()).addTransition(TaskAttemptState.NEW, TaskAttemptState.FAILED, TaskAttemptEventType.TA_FAILMSG, new FailedTransition()).addTransition(TaskAttemptState.UNASSIGNED, TaskAttemptState.ASSIGNED, TaskAttemptEventType.TA_ASSIGNED, new ContainerAssignedTransition()).addTransition(TaskAttemptState.UNASSIGNED, TaskAttemptState.KILLED, TaskAttemptEventType.TA_KILL, new DeallocateContainerTransition(TaskAttemptState.KILLED, true)).addTransition(TaskAttemptState.UNASSIGNED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_FAILMSG, new DeallocateContainerTransition(TaskAttemptState.FAILED, true)).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.RUNNING, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, new LaunchedContainerTransition()).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.ASSIGNED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_CONTAINER_LAUNCH_FAILED, new DeallocateContainerTransition(TaskAttemptState.FAILED, false)).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_CONTAINER_COMPLETED, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_KILL, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.ASSIGNED, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_FAILMSG, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.RUNNING, TaskAttemptEventType.TA_UPDATE, new StatusUpdater()).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.RUNNING, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DONE, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.COMMIT_PENDING, TaskAttemptEventType.TA_COMMIT_PENDING, new CommitPendingTransition()).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_FAILMSG, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_CONTAINER_COMPLETED, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_TIMED_OUT, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.RUNNING, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_KILL, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.COMMIT_PENDING, TaskAttemptEventType.TA_UPDATE, new StatusUpdater()).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.COMMIT_PENDING, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DONE, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_KILL, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_FAILMSG, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_CONTAINER_COMPLETED, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.COMMIT_PENDING, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_TIMED_OUT, CLEANUP_CONTAINER_TRANSITION).addTransition(TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptState.SUCCEEDED, TaskAttemptEventType.TA_CONTAINER_CLEANED, new SucceededTransition()).addTransition(TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, TaskAttemptState.SUCCESS_CONTAINER_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_TIMED_OUT, TaskAttemptEventType.TA_CONTAINER_COMPLETED)).addTransition(TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptEventType.TA_CONTAINER_CLEANED, new TaskCleanupTransition()).addTransition(TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.FAIL_CONTAINER_CLEANUP, TaskAttemptState.FAIL_CONTAINER_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_TIMED_OUT)).addTransition(TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptEventType.TA_CONTAINER_CLEANED, new TaskCleanupTransition()).addTransition(TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.KILL_CONTAINER_CLEANUP, TaskAttemptState.KILL_CONTAINER_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_TIMED_OUT)).addTransition(TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptState.FAILED, TaskAttemptEventType.TA_CLEANUP_DONE, new FailedTransition()).addTransition(TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.FAIL_TASK_CLEANUP, TaskAttemptState.FAIL_TASK_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).addTransition(TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptState.KILLED, TaskAttemptEventType.TA_CLEANUP_DONE, new KilledTransition()).addTransition(TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.KILL_TASK_CLEANUP, TaskAttemptState.KILL_TASK_CLEANUP, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).addTransition(//only possible for map attempts
    TaskAttemptState.SUCCEEDED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE, new TooManyFetchFailureTransition()).addTransition(TaskAttemptState.SUCCEEDED, TaskAttemptState.SUCCEEDED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.SUCCEEDED, TaskAttemptState.SUCCEEDED, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_FAILMSG, TaskAttemptEventType.TA_CONTAINER_COMPLETED)).addTransition(TaskAttemptState.FAILED, TaskAttemptState.FAILED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.FAILED, TaskAttemptState.FAILED, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_ASSIGNED, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).addTransition(TaskAttemptState.KILLED, TaskAttemptState.KILLED, TaskAttemptEventType.TA_DIAGNOSTICS_UPDATE, DIAGNOSTIC_INFORMATION_UPDATE_TRANSITION).addTransition(TaskAttemptState.KILLED, TaskAttemptState.KILLED, EnumSet.of(TaskAttemptEventType.TA_KILL, TaskAttemptEventType.TA_ASSIGNED, TaskAttemptEventType.TA_CONTAINER_COMPLETED, TaskAttemptEventType.TA_UPDATE, TaskAttemptEventType.TA_CONTAINER_LAUNCHED, TaskAttemptEventType.TA_COMMIT_PENDING, TaskAttemptEventType.TA_DONE, TaskAttemptEventType.TA_FAILMSG)).installTopology();

    private final StateMachine<TaskAttemptState, TaskAttemptEventType, TaskAttemptEvent> stateMachine;

    private ContainerId containerID;

    private NodeId containerNodeId;

    private String containerMgrAddress;

    private String nodeHttpAddress;

    private String nodeRackName;

    private WrappedJvmID jvmID;

    private ContainerToken containerToken;

    private Resource assignedCapability;

    //this takes good amount of memory ~ 30KB. Instantiate it lazily
    //and make it null once task is launched.
    private org.apache.hadoop.mapred.Task remoteTask;

    //this is the last status reported by the REMOTE running attempt
    private TaskAttemptStatus reportedStatus;

    private static final String LINE_SEPARATOR = System.getProperty("line.separator");

    public TaskAttemptImpl(TaskId taskId, int i, EventHandler eventHandler, TaskAttemptListener taskAttemptListener, Path jobFile, int partition, JobConf conf, String[] dataLocalHosts, OutputCommitter committer, Token<JobTokenIdentifier> jobToken, Collection<Token<? extends TokenIdentifier>> fsTokens, Clock clock) {
        oldJobId = TypeConverter.fromYarn(taskId.getJobId());
        this.conf = conf;
        this.clock = clock;
        attemptId = recordFactory.newRecordInstance(TaskAttemptId.class);
        attemptId.setTaskId(taskId);
        attemptId.setId(i);
        this.taskAttemptListener = taskAttemptListener;
        // Initialize reportedStatus
        reportedStatus = new TaskAttemptStatus();
        initTaskAttemptStatus(reportedStatus);
        ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
        readLock = readWriteLock.readLock();
        writeLock = readWriteLock.writeLock();
        this.fsTokens = fsTokens;
        this.jobToken = jobToken;
        this.eventHandler = eventHandler;
        this.committer = committer;
        this.jobFile = jobFile;
        this.partition = partition;
        //TODO:create the resource reqt for this Task attempt
        this.resourceCapability = recordFactory.newRecordInstance(Resource.class);
        this.resourceCapability.setMemory(getMemoryRequired(conf, taskId.getTaskType()));
        this.dataLocalHosts = dataLocalHosts;
        RackResolver.init(conf);
        // This "this leak" is okay because the retained pointer is in an
        //  instance variable.
        stateMachine = stateMachineFactory.make(this);
    }

    private int getMemoryRequired(Configuration conf, TaskType taskType) {
        int memory = 1024;
        if (taskType == TaskType.MAP) {
            memory = conf.getInt(MRJobConfig.MAP_MEMORY_MB, MAP_MEMORY_MB_DEFAULT);
        } else if (taskType == TaskType.REDUCE) {
            memory = conf.getInt(MRJobConfig.REDUCE_MEMORY_MB, REDUCE_MEMORY_MB_DEFAULT);
        }
        return memory;
    }

    /**
   * Create a {@link LocalResource} record with all the given parameters.
   */
    private static LocalResource createLocalResource(FileSystem fc, Path file, LocalResourceType type, LocalResourceVisibility visibility) throws IOException {
        FileStatus fstat = fc.getFileStatus(file);
        URL resourceURL = ConverterUtils.getYarnUrlFromPath(fc.resolvePath(fstat.getPath()));
        long resourceSize = fstat.getLen();
        long resourceModificationTime = fstat.getModificationTime();
        return BuilderUtils.newLocalResource(resourceURL, type, visibility, resourceSize, resourceModificationTime);
    }

    /**
   * Lock this on initialClasspath so that there is only one fork in the AM for
   * getting the initial class-path. TODO: We already construct
   * a parent CLC and use it for all the containers, so this should go away
   * once the mr-generated-classpath stuff is gone.
   */
    private static String getInitialClasspath(Configuration conf) throws IOException {
        synchronized (classpathLock) {
            if (initialClasspathFlag.get()) {
                return initialClasspath;
            }
            Map<String, String> env = new HashMap<String, String>();
            MRApps.setClasspath(env, conf);
            initialClasspath = env.get(Environment.CLASSPATH.name());
            initialClasspathFlag.set(true);
            return initialClasspath;
        }
    }

    /**
   * Create the common {@link ContainerLaunchContext} for all attempts.
   * @param applicationACLs 
   */
    private static ContainerLaunchContext createCommonContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, Configuration conf, Token<JobTokenIdentifier> jobToken, final org.apache.hadoop.mapred.JobID oldJobId, Collection<Token<? extends TokenIdentifier>> fsTokens) {
        // Application resources
        Map<String, LocalResource> localResources = new HashMap<String, LocalResource>();
        // Application environment
        Map<String, String> environment = new HashMap<String, String>();
        // Service data
        Map<String, ByteBuffer> serviceData = new HashMap<String, ByteBuffer>();
        // Tokens
        ByteBuffer tokens = ByteBuffer.wrap(new byte[] {});
        try {
            FileSystem remoteFS = FileSystem.get(conf);
            // //////////// Set up JobJar to be localized properly on the remote NM.
            String jobJar = conf.get(MRJobConfig.JAR);
            if (jobJar != null) {
                Path remoteJobJar = (new Path(jobJar)).makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory());
                localResources.put(MRJobConfig.JOB_JAR, createLocalResource(remoteFS, remoteJobJar, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION));
                LOG.info("The job-jar file on the remote FS is " + remoteJobJar.toUri().toASCIIString());
            } else {
                // Job jar may be null. For e.g, for pipes, the job jar is the hadoop
                // mapreduce jar itself which is already on the classpath.
                LOG.info("Job jar is not present. " + "Not adding any jar to the list of resources.");
            }
            // //////////// End of JobJar setup
            // //////////// Set up JobConf to be localized properly on the remote NM.
            Path path = MRApps.getStagingAreaDir(conf, UserGroupInformation.getCurrentUser().getShortUserName());
            Path remoteJobSubmitDir = new Path(path, oldJobId.toString());
            Path remoteJobConfPath = new Path(remoteJobSubmitDir, MRJobConfig.JOB_CONF_FILE);
            localResources.put(MRJobConfig.JOB_CONF_FILE, createLocalResource(remoteFS, remoteJobConfPath, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION));
            LOG.info("The job-conf file on the remote FS is " + remoteJobConfPath.toUri().toASCIIString());
            // //////////// End of JobConf setup
            // Setup DistributedCache
            MRApps.setupDistributedCache(conf, localResources);
            // Setup up tokens
            Credentials taskCredentials = new Credentials();
            if (UserGroupInformation.isSecurityEnabled()) {
                // Add file-system tokens
                for (Token<? extends TokenIdentifier> token : fsTokens) {
                    LOG.info("Putting fs-token for NM use for launching container : " + token.toString());
                    taskCredentials.addToken(token.getService(), token);
                }
            }
            // LocalStorageToken is needed irrespective of whether security is enabled
            // or not.
            TokenCache.setJobToken(jobToken, taskCredentials);
            DataOutputBuffer containerTokens_dob = new DataOutputBuffer();
            LOG.info("Size of containertokens_dob is " + taskCredentials.numberOfTokens());
            taskCredentials.writeTokenStorageToStream(containerTokens_dob);
            tokens = ByteBuffer.wrap(containerTokens_dob.getData(), 0, containerTokens_dob.getLength());
            // Add shuffle token
            LOG.info("Putting shuffle token in serviceData");
            serviceData.put(ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID, ShuffleHandler.serializeServiceData(jobToken));
            Apps.addToEnvironment(environment, Environment.CLASSPATH.name(), getInitialClasspath(conf));
        } catch (IOException e) {
            throw new YarnException(e);
        }
        // Shell
        environment.put(Environment.SHELL.name(), conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL, MRJobConfig.DEFAULT_SHELL));
        // Add pwd to LD_LIBRARY_PATH, add this before adding anything else
        Apps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(), Environment.PWD.$());
        // Add the env variables passed by the admin
        Apps.setEnvFromInputString(environment, conf.get(MRJobConfig.MAPRED_ADMIN_USER_ENV, MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV));
        // Construct the actual Container
        // The null fields are per-container and will be constructed for each
        // container separately.
        ContainerLaunchContext container = BuilderUtils.newContainerLaunchContext(null, conf.get(MRJobConfig.USER_NAME), null, localResources, environment, null, serviceData, tokens, applicationACLs);
        return container;
    }

    static ContainerLaunchContext createContainerLaunchContext(Map<ApplicationAccessType, String> applicationACLs, ContainerId containerID, Configuration conf, Token<JobTokenIdentifier> jobToken, Task remoteTask, final org.apache.hadoop.mapred.JobID oldJobId, Resource assignedCapability, WrappedJvmID jvmID, TaskAttemptListener taskAttemptListener, Collection<Token<? extends TokenIdentifier>> fsTokens) {
        synchronized (commonContainerSpecLock) {
            if (commonContainerSpec == null) {
                commonContainerSpec = createCommonContainerLaunchContext(applicationACLs, conf, jobToken, oldJobId, fsTokens);
            }
        }
        // Fill in the fields needed per-container that are missing in the common
        // spec.
        // Setup environment by cloning from common env.
        Map<String, String> env = commonContainerSpec.getEnvironment();
        Map<String, String> myEnv = new HashMap<String, String>(env.size());
        myEnv.putAll(env);
        MapReduceChildJVM.setVMEnv(myEnv, remoteTask);
        // Set up the launch command
        List<String> commands = MapReduceChildJVM.getVMCommand(taskAttemptListener.getAddress(), remoteTask, jvmID);
        // Duplicate the ByteBuffers for access by multiple containers.
        Map<String, ByteBuffer> myServiceData = new HashMap<String, ByteBuffer>();
        for (Entry<String, ByteBuffer> entry : commonContainerSpec.getServiceData().entrySet()) {
            myServiceData.put(entry.getKey(), entry.getValue().duplicate());
        }
        // Construct the actual Container
        ContainerLaunchContext container = BuilderUtils.newContainerLaunchContext(containerID, commonContainerSpec.getUser(), assignedCapability, commonContainerSpec.getLocalResources(), myEnv, commands, myServiceData, commonContainerSpec.getContainerTokens().duplicate(), applicationACLs);
        return container;
    }

    @Override
    public ContainerId getAssignedContainerID() {
        readLock.lock();
        try {
            return containerID;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public String getAssignedContainerMgrAddress() {
        readLock.lock();
        try {
            return containerMgrAddress;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getLaunchTime() {
        readLock.lock();
        try {
            return launchTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getFinishTime() {
        readLock.lock();
        try {
            return finishTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getShuffleFinishTime() {
        readLock.lock();
        try {
            return this.reportedStatus.shuffleFinishTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public long getSortFinishTime() {
        readLock.lock();
        try {
            return this.reportedStatus.sortFinishTime;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public int getShufflePort() {
        readLock.lock();
        try {
            return shufflePort;
        } finally {
            readLock.unlock();
        }
    }

    /**If container Assigned then return the node's address, otherwise null.
   */
    @Override
    public String getNodeHttpAddress() {
        readLock.lock();
        try {
            return nodeHttpAddress;
        } finally {
            readLock.unlock();
        }
    }

    /**
   * If container Assigned then return the node's rackname, otherwise null.
   */
    @Override
    public String getNodeRackName() {
        this.readLock.lock();
        try {
            return this.nodeRackName;
        } finally {
            this.readLock.unlock();
        }
    }

    protected abstract org.apache.hadoop.mapred.Task createRemoteTask();

    @Override
    public TaskAttemptId getID() {
        return attemptId;
    }

    @Override
    public boolean isFinished() {
        readLock.lock();
        try {
            // TODO: Use stateMachine level method?
            return (getState() == TaskAttemptState.SUCCEEDED || getState() == TaskAttemptState.FAILED || getState() == TaskAttemptState.KILLED);
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public TaskAttemptReport getReport() {
        TaskAttemptReport result = recordFactory.newRecordInstance(TaskAttemptReport.class);
        readLock.lock();
        try {
            result.setTaskAttemptId(attemptId);
            //take the LOCAL state of attempt
            //DO NOT take from reportedStatus
            result.setTaskAttemptState(getState());
            result.setProgress(reportedStatus.progress);
            result.setStartTime(launchTime);
            result.setFinishTime(finishTime);
            result.setShuffleFinishTime(this.reportedStatus.shuffleFinishTime);
            result.setDiagnosticInfo(StringUtils.join(LINE_SEPARATOR, getDiagnostics()));
            result.setPhase(reportedStatus.phase);
            result.setStateString(reportedStatus.stateString);
            result.setCounters(TypeConverter.toYarn(getCounters()));
            result.setContainerId(this.getAssignedContainerID());
            result.setNodeManagerHost(trackerName);
            result.setNodeManagerHttpPort(httpPort);
            if (this.containerNodeId != null) {
                result.setNodeManagerPort(this.containerNodeId.getPort());
            }
            return result;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public List<String> getDiagnostics() {
        List<String> result = new ArrayList<String>();
        readLock.lock();
        try {
            result.addAll(diagnostics);
            return result;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public Counters getCounters() {
        readLock.lock();
        try {
            Counters counters = reportedStatus.counters;
            if (counters == null) {
                counters = EMPTY_COUNTERS;
            //        counters.groups = new HashMap<String, CounterGroup>();
            }
            return counters;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public float getProgress() {
        readLock.lock();
        try {
            return reportedStatus.progress;
        } finally {
            readLock.unlock();
        }
    }

    @Override
    public TaskAttemptState getState() {
        readLock.lock();
        try {
            return stateMachine.getCurrentState();
        } finally {
            readLock.unlock();
        }
    }

    @SuppressWarnings("unchecked")
    @Override
    public void handle(TaskAttemptEvent event) {
        if (LOG.isDebugEnabled()) {
            LOG.debug("Processing " + event.getTaskAttemptID() + " of type " + event.getType());
        }
        writeLock.lock();
        try {
            final TaskAttemptState oldState = getState();
            try {
        DFix_EventWait(event);
 DFix_Signal();

            } catch (InvalidStateTransitonException e) {
                //        if (event.getType().toString().equals("TA_DIAGNOSTICS_UPDATE")){
                //            eventHandler.handle(event);
                //	      try {Thread.sleep(900);} catch (Exception _e){}
                //            LOG.info("DIG event is reput to the queue ------- ");
                //            writeLock.unlock();
                //	    return;
                //        }
                LOG.info(event.getType());
                LOG.error("Can't handle this event at current state for " + this.attemptId, e);
                eventHandler.handle(new JobDiagnosticsUpdateEvent(this.attemptId.getTaskId().getJobId(), "Invalid event " + event.getType() + " on TaskAttempt " + this.attemptId));
                eventHandler.handle(new JobEvent(this.attemptId.getTaskId().getJobId(), JobEventType.INTERNAL_ERROR));
            }
            if (oldState != getState()) {
                LOG.info(attemptId + " TaskAttempt Transitioned from " + oldState + " to " + getState());
            }
        } finally {
            writeLock.unlock();
        }
    }

    //always called in write lock
    private void setFinishTime() {
        //set the finish time only if launch time is set
        if (launchTime != 0) {
            finishTime = clock.getTime();
        }
    }

    private static long computeSlotMillis(TaskAttemptImpl taskAttempt) {
        TaskType taskType = taskAttempt.getID().getTaskId().getTaskType();
        int slotMemoryReq = taskAttempt.getMemoryRequired(taskAttempt.conf, taskType);
        int simSlotsRequired = slotMemoryReq / (taskType == TaskType.MAP ? MAP_MEMORY_MB_DEFAULT : REDUCE_MEMORY_MB_DEFAULT);
        // Simulating MRv1 slots for counters by assuming *_MEMORY_MB_DEFAULT
        // corresponds to a MrV1 slot.
        // Fallow slot millis is not applicable in MRv2 - since a container is
        // either assigned with the required memory or is not. No partial
        // reserveations
        long slotMillisIncrement = simSlotsRequired * (taskAttempt.getFinishTime() - taskAttempt.getLaunchTime());
        return slotMillisIncrement;
    }

    private static JobCounterUpdateEvent createJobCounterUpdateEventTAFailed(TaskAttemptImpl taskAttempt) {
        TaskType taskType = taskAttempt.getID().getTaskId().getTaskType();
        JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskAttempt.getID().getTaskId().getJobId());
        long slotMillisIncrement = computeSlotMillis(taskAttempt);
        if (taskType == TaskType.MAP) {
            jce.addCounterUpdate(JobCounter.NUM_FAILED_MAPS, 1);
            jce.addCounterUpdate(JobCounter.SLOTS_MILLIS_MAPS, slotMillisIncrement);
        } else {
            jce.addCounterUpdate(JobCounter.NUM_FAILED_REDUCES, 1);
            jce.addCounterUpdate(JobCounter.SLOTS_MILLIS_REDUCES, slotMillisIncrement);
        }
        return jce;
    }

    private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {
        TaskAttemptUnsuccessfulCompletionEvent tauce = new TaskAttemptUnsuccessfulCompletionEvent(TypeConverter.fromYarn(taskAttempt.attemptId), TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()), attemptState.toString(), taskAttempt.finishTime, taskAttempt.containerNodeId == null ? "UNKNOWN" : taskAttempt.containerNodeId.getHost(), taskAttempt.containerNodeId == null ? -1 : taskAttempt.containerNodeId.getPort(), taskAttempt.nodeRackName == null ? "UNKNOWN" : taskAttempt.nodeRackName, StringUtils.join(LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt.getProgressSplitBlock().burst());
        return tauce;
    }

    private WrappedProgressSplitsBlock getProgressSplitBlock() {
        readLock.lock();
        try {
            if (progressSplitBlock == null) {
                progressSplitBlock = new WrappedProgressSplitsBlock(conf.getInt(MRJobConfig.MR_AM_NUM_PROGRESS_SPLITS, MRJobConfig.DEFAULT_MR_AM_NUM_PROGRESS_SPLITS));
            }
            return progressSplitBlock;
        } finally {
            readLock.unlock();
        }
    }

    private void updateProgressSplits() {
        double newProgress = reportedStatus.progress;
        Counters counters = reportedStatus.counters;
        if (counters == null)
            return;
        WrappedProgressSplitsBlock splitsBlock = getProgressSplitBlock();
        if (splitsBlock != null) {
            long now = clock.getTime();
            // TODO Ensure not 0
            long start = getLaunchTime();
            if (start != 0 && now - start <= Integer.MAX_VALUE) {
                splitsBlock.getProgressWallclockTime().extend(newProgress, (int) (now - start));
            }
            Counter cpuCounter = counters.findCounter(TaskCounter.CPU_MILLISECONDS);
            if (cpuCounter != null && cpuCounter.getValue() <= Integer.MAX_VALUE) {
                splitsBlock.getProgressCPUTime().extend(newProgress, // long to int? TODO: FIX. Same below
                (int) cpuCounter.getValue());
            }
            Counter virtualBytes = counters.findCounter(TaskCounter.VIRTUAL_MEMORY_BYTES);
            if (virtualBytes != null) {
                splitsBlock.getProgressVirtualMemoryKbytes().extend(newProgress, (int) (virtualBytes.getValue() / (MEMORY_SPLITS_RESOLUTION)));
            }
            Counter physicalBytes = counters.findCounter(TaskCounter.PHYSICAL_MEMORY_BYTES);
            if (physicalBytes != null) {
                splitsBlock.getProgressPhysicalMemoryKbytes().extend(newProgress, (int) (physicalBytes.getValue() / (MEMORY_SPLITS_RESOLUTION)));
            }
        }
    }

    static class RequestContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        private final boolean rescheduled;

        public RequestContainerTransition(boolean rescheduled) {
            this.rescheduled = rescheduled;
        }

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // Tell any speculator that we're requesting a container
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.getID().getTaskId(), +1));
            //request for container
            if (rescheduled) {
                taskAttempt.eventHandler.handle(ContainerRequestEvent.createContainerRequestEventForFailedContainer(taskAttempt.attemptId, taskAttempt.resourceCapability));
            } else {
                Set<String> racks = new HashSet<String>();
                for (String host : taskAttempt.dataLocalHosts) {
                    racks.add(RackResolver.resolve(host).getNetworkLocation());
                }
                taskAttempt.eventHandler.handle(new ContainerRequestEvent(taskAttempt.attemptId, taskAttempt.resourceCapability, taskAttempt.resolveHosts(taskAttempt.dataLocalHosts), racks.toArray(new String[racks.size()])));
            }
        }
    }

    protected String[] resolveHosts(String[] src) {
        String[] result = new String[src.length];
        for (int i = 0; i < src.length; i++) {
            if (isIP(src[i])) {
                result[i] = resolveHost(src[i]);
            } else {
                result[i] = src[i];
            }
        }
        return result;
    }

    protected String resolveHost(String src) {
        // Fallback in case of failure.
        String result = src;
        try {
            InetAddress addr = InetAddress.getByName(src);
            result = addr.getHostName();
        } catch (UnknownHostException e) {
            LOG.warn("Failed to resolve address: " + src + ". Continuing to use the same.");
        }
        return result;
    }

    private static final // Pattern for matching ip
    Pattern ipPattern = Pattern.compile("\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}");

    protected boolean isIP(String src) {
        return ipPattern.matcher(src).matches();
    }

    private static class ContainerAssignedTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings({ "unchecked" })
        @Override
        public void transition(final TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            final TaskAttemptContainerAssignedEvent cEvent = (TaskAttemptContainerAssignedEvent) event;
            taskAttempt.containerID = cEvent.getContainer().getId();
            taskAttempt.containerNodeId = cEvent.getContainer().getNodeId();
            taskAttempt.containerMgrAddress = taskAttempt.containerNodeId.toString();
            taskAttempt.nodeHttpAddress = cEvent.getContainer().getNodeHttpAddress();
            taskAttempt.nodeRackName = RackResolver.resolve(taskAttempt.containerNodeId.getHost()).getNetworkLocation();
            taskAttempt.containerToken = cEvent.getContainer().getContainerToken();
            taskAttempt.assignedCapability = cEvent.getContainer().getResource();
            // this is a _real_ Task (classic Hadoop mapred flavor):
            taskAttempt.remoteTask = taskAttempt.createRemoteTask();
            taskAttempt.jvmID = new WrappedJvmID(taskAttempt.remoteTask.getTaskID().getJobID(), taskAttempt.remoteTask.isMapTask(), taskAttempt.containerID.getId());
            taskAttempt.taskAttemptListener.registerPendingTask(taskAttempt.remoteTask, taskAttempt.jvmID);
            //launch the container
            //create the container object to be launched for a given Task attempt
            ContainerLaunchContext launchContext = createContainerLaunchContext(cEvent.getApplicationACLs(), taskAttempt.containerID, taskAttempt.conf, taskAttempt.jobToken, taskAttempt.remoteTask, taskAttempt.oldJobId, taskAttempt.assignedCapability, taskAttempt.jvmID, taskAttempt.taskAttemptListener, taskAttempt.fsTokens);
            taskAttempt.eventHandler.handle(new ContainerRemoteLaunchEvent(taskAttempt.attemptId, taskAttempt.containerID, taskAttempt.containerMgrAddress, taskAttempt.containerToken, launchContext, taskAttempt.remoteTask));
            // send event to speculator that our container needs are satisfied
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));
        }
    }

    private static class DeallocateContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        private final TaskAttemptState finalState;

        private final boolean withdrawsContainerRequest;

        DeallocateContainerTransition(TaskAttemptState finalState, boolean withdrawsContainerRequest) {
            this.finalState = finalState;
            this.withdrawsContainerRequest = withdrawsContainerRequest;
        }

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //set the finish time
            taskAttempt.setFinishTime();
            //send the deallocate event to ContainerAllocator
            taskAttempt.eventHandler.handle(new ContainerAllocatorEvent(taskAttempt.attemptId, ContainerAllocator.EventType.CONTAINER_DEALLOCATE));
            //  we're transitioning out of UNASSIGNED
            if (withdrawsContainerRequest) {
                taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.getID().getTaskId(), -1));
            }
            switch(finalState) {
                case FAILED:
                    taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_FAILED));
                    break;
                case KILLED:
                    taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_KILLED));
                    break;
            }
            if (taskAttempt.getLaunchTime() != 0) {
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, finalState);
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
        }
    }

    private static class LaunchedContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent evnt) {
            TaskAttemptContainerLaunchedEvent event = (TaskAttemptContainerLaunchedEvent) evnt;
            //set the launch time
            taskAttempt.launchTime = taskAttempt.clock.getTime();
            taskAttempt.shufflePort = event.getShufflePort();
            // register it to TaskAttemptListener so that it can start monitoring it.
            taskAttempt.taskAttemptListener.registerLaunchedTask(taskAttempt.attemptId, taskAttempt.jvmID);
            //TODO Resolve to host / IP in case of a local address.
            InetSocketAddress nodeHttpInetAddr = // TODO:
            NetUtils.createSocketAddr(taskAttempt.nodeHttpAddress);
            // Costly?
            taskAttempt.trackerName = nodeHttpInetAddr.getHostName();
            taskAttempt.httpPort = nodeHttpInetAddr.getPort();
            JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskAttempt.attemptId.getTaskId().getJobId());
            jce.addCounterUpdate(taskAttempt.attemptId.getTaskId().getTaskType() == TaskType.MAP ? JobCounter.TOTAL_LAUNCHED_MAPS : JobCounter.TOTAL_LAUNCHED_REDUCES, 1);
            taskAttempt.eventHandler.handle(jce);
            LOG.info("TaskAttempt: [" + taskAttempt.attemptId + "] using containerId: [" + taskAttempt.containerID + " on NM: [" + taskAttempt.containerMgrAddress + "]");
            TaskAttemptStartedEvent tase = new TaskAttemptStartedEvent(TypeConverter.fromYarn(taskAttempt.attemptId), TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()), taskAttempt.launchTime, nodeHttpInetAddr.getHostName(), nodeHttpInetAddr.getPort(), taskAttempt.shufflePort, taskAttempt.containerID);
            taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tase));
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.attemptId, true, taskAttempt.clock.getTime()));
            //make remoteTask reference as null as it is no more needed
            //and free up the memory
            taskAttempt.remoteTask = null;
            //tell the Task that attempt has started
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_LAUNCHED));
        }
    }

    private static class CommitPendingTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_COMMIT_PENDING));
        }
    }

    private static class TaskCleanupTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            TaskAttemptContext taskContext = new TaskAttemptContextImpl(taskAttempt.conf, TypeConverter.fromYarn(taskAttempt.attemptId));
            taskAttempt.eventHandler.handle(new TaskCleanupEvent(taskAttempt.attemptId, taskAttempt.committer, taskContext));
        }
    }

    private static class SucceededTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //set the finish time
            taskAttempt.setFinishTime();
            long slotMillis = computeSlotMillis(taskAttempt);
            TaskId taskId = taskAttempt.attemptId.getTaskId();
            JobCounterUpdateEvent jce = new JobCounterUpdateEvent(taskId.getJobId());
            jce.addCounterUpdate(taskId.getTaskType() == TaskType.MAP ? JobCounter.SLOTS_MILLIS_MAPS : JobCounter.SLOTS_MILLIS_REDUCES, slotMillis);
            taskAttempt.eventHandler.handle(jce);
            taskAttempt.logAttemptFinishedEvent(TaskAttemptState.SUCCEEDED);
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_SUCCEEDED));
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.reportedStatus, taskAttempt.clock.getTime()));
        }
    }

    private static class FailedTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // set the finish time
            taskAttempt.setFinishTime();
            if (taskAttempt.getLaunchTime() != 0) {
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, TaskAttemptState.FAILED);
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            // taskAttempt.logAttemptFinishedEvent(TaskAttemptState.FAILED); Not
            // handling failed map/reduce events.
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_FAILED));
        }
    }

    @SuppressWarnings({ "unchecked" })
    private void logAttemptFinishedEvent(TaskAttemptState state) {
        //Log finished events only if an attempt started.
        if (getLaunchTime() == 0)
            return;
        if (attemptId.getTaskId().getTaskType() == TaskType.MAP) {
            MapAttemptFinishedEvent mfe = new MapAttemptFinishedEvent(TypeConverter.fromYarn(attemptId), TypeConverter.fromYarn(attemptId.getTaskId().getTaskType()), state.toString(), this.reportedStatus.mapFinishTime, finishTime, this.containerNodeId == null ? "UNKNOWN" : this.containerNodeId.getHost(), this.containerNodeId == null ? -1 : this.containerNodeId.getPort(), this.nodeRackName == null ? "UNKNOWN" : this.nodeRackName, this.reportedStatus.stateString, getCounters(), getProgressSplitBlock().burst());
            eventHandler.handle(new JobHistoryEvent(attemptId.getTaskId().getJobId(), mfe));
        } else {
            ReduceAttemptFinishedEvent rfe = new ReduceAttemptFinishedEvent(TypeConverter.fromYarn(attemptId), TypeConverter.fromYarn(attemptId.getTaskId().getTaskType()), state.toString(), this.reportedStatus.shuffleFinishTime, this.reportedStatus.sortFinishTime, finishTime, this.containerNodeId == null ? "UNKNOWN" : this.containerNodeId.getHost(), this.containerNodeId == null ? -1 : this.containerNodeId.getPort(), this.nodeRackName == null ? "UNKNOWN" : this.nodeRackName, this.reportedStatus.stateString, getCounters(), getProgressSplitBlock().burst());
            eventHandler.handle(new JobHistoryEvent(attemptId.getTaskId().getJobId(), rfe));
        }
    }

    private static class TooManyFetchFailureTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //add to diagnostic
            taskAttempt.addDiagnosticInfo("Too Many fetch failures.Failing the attempt");
            //set the finish time
            taskAttempt.setFinishTime();
            if (taskAttempt.getLaunchTime() != 0) {
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, TaskAttemptState.FAILED);
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_FAILED));
        }
    }

    private static class KilledTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            //set the finish time
            taskAttempt.setFinishTime();
            if (taskAttempt.getLaunchTime() != 0) {
                taskAttempt.eventHandler.handle(createJobCounterUpdateEventTAFailed(taskAttempt));
                TaskAttemptUnsuccessfulCompletionEvent tauce = createTaskAttemptUnsuccessfulCompletionEvent(taskAttempt, TaskAttemptState.KILLED);
                taskAttempt.eventHandler.handle(new JobHistoryEvent(taskAttempt.attemptId.getTaskId().getJobId(), tauce));
            } else {
                LOG.debug("Not generating HistoryFinish event since start event not generated for taskAttempt: " + taskAttempt.getID());
            }
            //      taskAttempt.logAttemptFinishedEvent(TaskAttemptState.KILLED); Not logging Map/Reduce attempts in case of failure.
            taskAttempt.eventHandler.handle(new TaskTAttemptEvent(taskAttempt.attemptId, TaskEventType.T_ATTEMPT_KILLED));
        }
    }

    private static class CleanupContainerTransition implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // unregister it to TaskAttemptListener so that it stops listening
            // for it
            taskAttempt.taskAttemptListener.unregister(taskAttempt.attemptId, taskAttempt.jvmID);
            taskAttempt.reportedStatus.progress = 1.0f;
            taskAttempt.updateProgressSplits();
            //send the cleanup event to containerLauncher
            taskAttempt.eventHandler.handle(new ContainerLauncherEvent(taskAttempt.attemptId, taskAttempt.containerID, taskAttempt.containerMgrAddress, taskAttempt.containerToken, ContainerLauncher.EventType.CONTAINER_REMOTE_CLEANUP));
        }
    }

    private void addDiagnosticInfo(String diag) {
        if (diag != null && !diag.equals("")) {
            diagnostics.add(diag);
        }
    }

    private static class StatusUpdater implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @SuppressWarnings("unchecked")
        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            // Status update calls don't really change the state of the attempt.
            TaskAttemptStatus newReportedStatus = ((TaskAttemptStatusUpdateEvent) event).getReportedTaskAttemptStatus();
            // Now switch the information in the reportedStatus
            taskAttempt.reportedStatus = newReportedStatus;
            taskAttempt.reportedStatus.taskState = taskAttempt.getState();
            // send event to speculator about the reported status
            taskAttempt.eventHandler.handle(new SpeculatorEvent(taskAttempt.reportedStatus, taskAttempt.clock.getTime()));
            taskAttempt.updateProgressSplits();
            //this only will happen in reduce attempt type
            if (taskAttempt.reportedStatus.fetchFailedMaps != null && taskAttempt.reportedStatus.fetchFailedMaps.size() > 0) {
                taskAttempt.eventHandler.handle(new JobTaskAttemptFetchFailureEvent(taskAttempt.attemptId, taskAttempt.reportedStatus.fetchFailedMaps));
            }
        }
    }

    private static class DiagnosticInformationUpdater implements SingleArcTransition<TaskAttemptImpl, TaskAttemptEvent> {

        @Override
        public void transition(TaskAttemptImpl taskAttempt, TaskAttemptEvent event) {
            TaskAttemptDiagnosticsUpdateEvent diagEvent = (TaskAttemptDiagnosticsUpdateEvent) event;
            LOG.info("Diagnostics report from " + taskAttempt.attemptId + ": " + diagEvent.getDiagnosticInfo());
            taskAttempt.addDiagnosticInfo(diagEvent.getDiagnosticInfo());
        }
    }

    private void initTaskAttemptStatus(TaskAttemptStatus result) {
        result.progress = 0.0f;
        result.phase = Phase.STARTING;
        result.stateString = "NEW";
        result.taskState = TaskAttemptState.NEW;
        Counters counters = EMPTY_COUNTERS;
        //    counters.groups = new HashMap<String, CounterGroup>();
        result.counters = counters;
    }

    public Semaphore se_dfix = new Semaphore(0);
}

        stateMachine.doTransition(event.getType(), event);
-> if (event.getType().equals("TA_DIAGNOSTICS_UPDATE"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);
0 occurence use replace instead of replacefirst
No change:
ADD CLONE : ---          stateMachine.doTransition(event.getType(), event);
+++  if (event.getType().equals("TA_DIAGNOSTICS_UPDATE"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);
set clone call org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl handle 926
--------  PATCH DETAILS  ---------

In the StateMachineFactory.java

+++    public static AtomicInteger dfixeventflag = new AtomicInteger();

In the ClientServiceDelegate.java

---          return methodOb.invoke(dfix_proxy, args);
+++  return DFix_Rpc();

In the TaskAttemptImpl.java

+++    public Semaphore se_dfix = new Semaphore(0);

---          stateMachine.doTransition(event.getType(), event);
+++          stateMachine.doTransition(event.getType(), event); DFix_Signal();


---          stateMachine.doTransition(event.getType(), event);
+++  DFix_EventWait(event);


In the MRClientService.java

---        appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL));
+++        appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL)); DFix_EventWait();

In the ClientServiceDelegate.java

DFix_Rpc():
while (true) {
try{
        return methodOb.invoke(dfix_proxy, args);
} catch(YarnRemoteExceptionPBImpl e_e){
if (!e_e.getMessage().contains("dfix")) throw e;
}
}


In the TaskAttemptImpl.java

DFix_Signal():
 if (event.getType().toString().equals("TA_ASSIGNED" ))se_dfix.release(9999);
 

DFix_EventWait(event):
if (event.getType().toString().equals("TA_DIAGNOSTICS_UPDATE")){
if (se_dfix.availablePermits() >1) {
if (StateMachineFactory.dfixeventflag.get() > 1000) {
StateMachineFactory.dfixeventflag.getAndDecrement(); return ;}
StateMachineFactory.dfixeventflag.getAndAdd(1000);
}else{
StateMachineFactory.dfixeventflag.getAndDecrement(); return ;}
}
        stateMachine.doTransition(event.getType(), event);

In the MRClientService.java

DFix_EventWait(): 
 int t_dfix=0;StateMachineFactory.dfixeventflag.getAndAdd(1);
while (true) { 
 try{ Thread.sleep(200); } catch (Exception e){}
 if (StateMachineFactory.dfixeventflag.get() >= 1000 ) break;
 t_dfix++; if (t_dfix > 20) throw new YarnRemoteExceptionPBImpl("dfix");
}

In the TaskAttemptImpl.java

---          stateMachine.doTransition(event.getType(), event);
+++  if (event.getType().equals("TA_ASSIGNED"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);

---          stateMachine.doTransition(event.getType(), event);
+++  if (event.getType().equals("TA_DIAGNOSTICS_UPDATE"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);

6 css loaded
1 css loaded
Cloning org/apache/hadoop/yarn/state/StateMachineFactory$InternalStateMachine doTransition 443 -> StateMachineFactory$InternalStateMachine
Fetch StateMachineFactory$InternalStateMachine from the CUTABLE
Clone functionorg/apache/hadoop/yarn/state/StateMachineFactory$InternalStateMachine doTransition 443
Cloning org/apache/hadoop/yarn/state/StateMachineFactory doTransition 298 -> StateMachineFactory
Fetch StateMachineFactory from the CUTABLE
Clone functionorg/apache/hadoop/yarn/state/StateMachineFactory doTransition 298
Cloning org/apache/hadoop/yarn/state/StateMachineFactory$SingleInternalArc doTransition 357 -> StateMachineFactory$SingleInternalArc
Fetch StateMachineFactory$SingleInternalArc from the CUTABLE
Clone functionorg/apache/hadoop/yarn/state/StateMachineFactory$SingleInternalArc doTransition 357
Cloning org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl$CleanupContainerTransition transition 1332 -> TaskAttemptImpl$CleanupContainerTransition
Fetch TaskAttemptImpl$CleanupContainerTransition from the CUTABLE
Clone functionorg/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl$CleanupContainerTransition transition 1332
Cloning org/apache/hadoop/mapred/TaskAttemptListenerImpl unregister 452 -> TaskAttemptListenerImpl
Fetch TaskAttemptListenerImpl from the CUTABLE
Clone functionorg/apache/hadoop/mapred/TaskAttemptListenerImpl unregister 452
Fetch TaskAttemptListenerImpl from the CUTABLE
    get CU to replace for MRClientService
      appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL));
->       appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL)); DFix_EventWait();
1 occurence use replace instead of replacefirst
Set the EE-Site wait to org/apache/hadoop/mapreduce/v2/app/client/MRClientService$MRClientProtocolHandler killTaskAttempt 346
Add signal to org/apache/hadoop/mapred/TaskAttemptListenerImpl getTask 419
Fetch TaskAttemptListenerImpl from the CUTABLE
~~~ add semaphore to TaskAttemptListenerImpl
    org.apache.hadoop.mapred.Task task = jvmIDToAttemptMap.get(wJvmID);
->     org.apache.hadoop.mapred.Task task = jvmIDToAttemptMap.get(wJvmID);DFix_Signal(jvmIDToAttemptMap,wJvmID);

1 occurence use replace instead of replacefirst
Found the callobject 
    get AnSString to replace for TaskAttemptListenerImpl
Multiple occurence of     jvmIDToAttemptMap.remove(jvmID); = 2!
    jvmIDToAttemptMap.remove(jvmID);
-> if (!DFix_CheckDrop()) return ;    jvmIDToAttemptMap.remove(jvmID);
setting rpc to org/apache/hadoop/mapreduce/v2/api/impl/pb/service/MRClientProtocolPBServiceImpl killTaskAttempt 217
    get CU to replace for MRClientProtocolPBServiceImpl
      response = real.killTaskAttempt(request);
->       response  = DFix_Rpc();
1 occurence use replace instead of replacefirst
RPC repeat added
    get CU to replace for TaskAttemptImpl
        stateMachine.doTransition(event.getType(), event);
-> if (event.getType().equals("TA_KILL"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);
1 occurence use replace instead of replacefirst
ADD CLONE : ---          stateMachine.doTransition(event.getType(), event);
+++  if (event.getType().equals("TA_KILL"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);
set clone call org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl handle 828
    get CU to replace for StateMachineFactory
Multiple occurence of       currentState = StateMachineFactory.this.doTransition(operand, currentState, eventType, event); = 2!
      currentState = StateMachineFactory.this.doTransition(operand, currentState, eventType, event);
->       currentState = StateMachineFactory.this.doTransition_dfix(operand, currentState, eventType, event);
ADD CLONE : ---        currentState = StateMachineFactory.this.doTransition(operand, currentState, eventType, event);
+++        currentState = StateMachineFactory.this.doTransition_dfix(operand, currentState, eventType, event);
set clone call org/apache/hadoop/yarn/state/StateMachineFactory$InternalStateMachine doTransition 443
    get AnSString to replace for StateMachineFactory
        return transition.doTransition(operand, oldState, event, eventType);
->         return transition.doTransition_dfix(operand, oldState, event, eventType);
1 occurence use replace instead of replacefirst
ADD CLONE : ---          return transition.doTransition(operand, oldState, event, eventType);
+++          return transition.doTransition_dfix(operand, oldState, event, eventType);
set clone call org/apache/hadoop/yarn/state/StateMachineFactory doTransition 298
    get AnSString to replace for StateMachineFactory
        hook.transition(operand, event);
->         hook.transition_dfix(operand, event);
1 occurence use replace instead of replacefirst
ADD CLONE : ---          hook.transition(operand, event);
+++          hook.transition_dfix(operand, event);
set clone call org/apache/hadoop/yarn/state/StateMachineFactory$SingleInternalArc doTransition 357
    get AnSString to replace for TaskAttemptImpl
      taskAttempt.taskAttemptListener.unregister(
->       taskAttempt.taskAttemptListener.unregister_dfix(
1 occurence use replace instead of replacefirst
ADD CLONE : ---        taskAttempt.taskAttemptListener.unregister(
+++        taskAttempt.taskAttemptListener.unregister_dfix(
set clone call org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl$CleanupContainerTransition transition 1332
--------  PATCH DETAILS  ---------

In the TaskAttemptListenerImpl.java

+++    public static AtomicInteger dfixeventflag = new AtomicInteger();

+++    public static HashMap<String, Semaphore > hm_dfix = new HashMap<String,Semaphore>();

---      org.apache.hadoop.mapred.Task task = jvmIDToAttemptMap.get(wJvmID);
+++      org.apache.hadoop.mapred.Task task = jvmIDToAttemptMap.get(wJvmID);DFix_Signal(jvmIDToAttemptMap,wJvmID);


---      jvmIDToAttemptMap.remove(jvmID);
+++  if (!DFix_CheckDrop()) return ;    jvmIDToAttemptMap.remove(jvmID);

In the MRClientService.java

---        appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL));
+++        appContext.getEventHandler().handle(new TaskAttemptEvent(taskAttemptId, TaskAttemptEventType.TA_KILL)); DFix_EventWait();

In the MRClientProtocolPBServiceImpl.java

---        response = real.killTaskAttempt(request);
+++        response  = DFix_Rpc();

In the TaskAttemptListenerImpl.java

DFix_Signal(jvmIDToAttemptMap,wJvmID):
String dfixkey = Integer.toString( System.identityHashCode(jvmIDToAttemptMap)) +Integer.toString( System.identityHashCode(wJvmID)) ;hm_dfix.put(dfixkey, new Semaphore(9999));


DFix_CheckDrop():
 String key =Integer.toString( System.identityHashCode(jvmIDToAttemptMap)) +Integer.toString( System.identityHashCode(jvmID)) ;if (hm_dfix.get(key)==null) {dfixeventflag.getAndDecrement(); return false ;}else{dfixeventflag.getAndAdd(1000);}    jvmIDToAttemptMap.remove(jvmID);
 return ture;


In the MRClientService.java

DFix_EventWait(): 
 int t_dfix=0;TaskAttemptListenerImpl.dfixeventflag.getAndAdd(1);
while (true) { 
 try{ Thread.sleep(200); } catch (Exception e){}
 if (TaskAttemptListenerImpl.dfixeventflag.get() >= 1000 ) break;
 t_dfix++; if (t_dfix > 20) throw new YarnRemoteExceptionPBImpl("dfix");
}

In the MRClientProtocolPBServiceImpl.java

DFix_Rpc():
while (true) {
try{
      response = real.killTaskAttempt(request);break;
} catch(YarnRemoteExceptionPBImpl e_e){
if (!e_e.getMessage().contains("dfix")) throw e;
}
}
return       response 


In the StateMachineFactory.java

---        currentState = StateMachineFactory.this.doTransition(operand, currentState, eventType, event);
+++        currentState = StateMachineFactory.this.doTransition_dfix(operand, currentState, eventType, event);

---          return transition.doTransition(operand, oldState, event, eventType);
+++          return transition.doTransition_dfix(operand, oldState, event, eventType);

---          hook.transition(operand, event);
+++          hook.transition_dfix(operand, event);

In the TaskAttemptImpl.java

---          stateMachine.doTransition(event.getType(), event);
+++  if (event.getType().equals("TA_KILL"))         stateMachine.doTransition_dfix(event.getType(), event); else         stateMachine.doTransition(event.getType(), event);

---        taskAttempt.taskAttemptListener.unregister(
+++        taskAttempt.taskAttemptListener.unregister_dfix(

No file exception
0 css loaded
0 css loaded
setting rpc to org/apache/hadoop/hbase/zookeeper/ZKAssign createOrForceNodeOffline 272
    get CU to replace for ZKAssign
    version = ZKUtil.checkExists(zkw, node);
->     version  = DFix_Rpc();
1 occurence use replace instead of replacefirst
RPC repeat added
--------  PATCH DETAILS  ---------

In the ZKAssign.java

---      version = ZKUtil.checkExists(zkw, node);
+++      version  = DFix_Rpc();

In the ZKAssign.java

DFix_Rpc():
String dfixcss = "";
for (StackTraceElement dfix_ste : Thread.currentThread().getStackTrace()) {dfixcss += dfix_ste.toString();}
while (version!=-1) {
    version = ZKUtil.checkExists(zkw, node);try{Thread.sleep(1000);}catch(Exception e_e){}
if (!dfixcss.contains("ServerShutdownHandler")) break;
}
return     version 


No file exception
0 css loaded
0 css loaded
setting rpc to org/apache/hadoop/hbase/master/AssignmentManager unassign 1751
    get CU to replace for AssignmentManager
          ZKAssign.createNodeClosing(master.getZooKeeper(), region, master.getServerName());
->   DFix_Rpc();
1 occurence use replace instead of replacefirst
RPC repeat added
--------  PATCH DETAILS  ---------

In the AssignmentManager.java

---            ZKAssign.createNodeClosing(master.getZooKeeper(), region, master.getServerName());
+++    DFix_Rpc();

In the AssignmentManager.java

DFix_Rpc():
while (true) {
try{
          ZKAssign.createNodeClosing(master.getZooKeeper(), region, master.getServerName());break;
} catch(KeeperException.NodeExistsException e_e){
}
}


2 css loaded
2 css loaded
Cloning org/apache/zookeeper/server/quorum/Leader lead 331 -> Leader
Fetch Leader from the CUTABLE
Clone functionorg/apache/zookeeper/server/quorum/Leader lead 331
Add signal to org/apache/zookeeper/server/quorum/Leader lead 331
Fetch Leader from the CUTABLE
~~~ add semaphore to Leader
Multiple occurence of             outstandingProposals.put(newLeaderProposal.packet.getZxid(), newLeaderProposal); = 2!
            outstandingProposals.put(newLeaderProposal.packet.getZxid(), newLeaderProposal);
->             outstandingProposals.put(newLeaderProposal.packet.getZxid(), newLeaderProposal); DFix_Signal();

    get CU to replace for LearnerHandler
Found the callobject leader
Multiple occurence of             leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress()); = 2!
            leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
-> DFix_Wait();            leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
    get CU to replace for QuorumPeer
                        leader.lead();
->                         leader.lead_dfix();
1 occurence use replace instead of replacefirst
ADD CLONE : ---                          leader.lead();
+++                          leader.lead_dfix();
set clone call org/apache/zookeeper/server/quorum/QuorumPeer run 746
--------  PATCH DETAILS  ---------

In the LearnerHandler.java

---              leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
+++  DFix_Wait();            leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());

In the Leader.java

+++    public Semaphore se_dfix = new Semaphore(0);

---              outstandingProposals.put(newLeaderProposal.packet.getZxid(), newLeaderProposal);
+++              outstandingProposals.put(newLeaderProposal.packet.getZxid(), newLeaderProposal); DFix_Signal();


In the LearnerHandler.java

leader.se_dfix.tryAcquire(1,7,java.util.concurrent.TimeUnit.SECONDS);

In the Leader.java

DFix_Signal():
se_dfix.release(9999);


In the QuorumPeer.java

---                          leader.lead();
+++                          leader.lead_dfix();

2 css loaded
2 css loaded
Cloning org/apache/zookeeper/server/quorum/Leader lead 337 -> Leader
Fetch Leader from the CUTABLE
Clone functionorg/apache/zookeeper/server/quorum/Leader lead 337
Cloning org/apache/zookeeper/server/quorum/Leader processAck 504 -> Leader
Fetch Leader from the CUTABLE
Clone functionorg/apache/zookeeper/server/quorum/Leader processAck 504
Add signal to org/apache/zookeeper/server/quorum/Leader lead 337
Fetch Leader from the CUTABLE
~~~ add semaphore to Leader
Multiple occurence of             newLeaderProposal.ackSet.add(self.getId()); = 2!
            newLeaderProposal.ackSet.add(self.getId());
-> DFix_Signal(newLeaderProposal.ackSet);

    get CU to replace for LearnerHandler
Multiple occurence of             leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress()); = 2!
            leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
-> DFix_Repeat();
    get AnSString to replace for Leader
Found the callobject 
NOT found ???  what's wrong???
        if (self.getQuorumVerifier().containsQuorum(p.ackSet)){              
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.zookeeper.server.quorum;

import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.net.BindException;
import java.net.ServerSocket;
import java.net.Socket;
import java.net.SocketAddress;
import java.net.SocketException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map.Entry;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.ConcurrentMap;
import org.apache.jute.BinaryOutputArchive;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.zookeeper.server.FinalRequestProcessor;
import org.apache.zookeeper.server.Request;
import org.apache.zookeeper.server.RequestProcessor;
import org.apache.zookeeper.server.quorum.QuorumPeer.LearnerType;
import org.apache.zookeeper.server.quorum.flexible.QuorumVerifier;
import org.apache.zookeeper.server.util.ZxidUtils;
import java.util.concurrent.Semaphore;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * This class has the control logic for the Leader.
 */
public class Leader {

    private static final Logger LOG = LoggerFactory.getLogger(Leader.class);

    private static final boolean nodelay = System.getProperty("leader.nodelay", "true").equals("true");

    static {
        LOG.info("TCP NoDelay set to: " + nodelay);
    }

    public static class Proposal {

        public QuorumPacket packet;

        public HashSet<Long> ackSet = new HashSet<Long>();

        public Request request;

        @Override
        public String toString() {
            return packet.getType() + ", " + packet.getZxid() + ", " + request;
        }
    }

    final LeaderZooKeeperServer zk;

    final QuorumPeer self;

    // the follower acceptor thread
    LearnerCnxAcceptor cnxAcceptor;

    // list of all the followers
    public final HashSet<LearnerHandler> learners = new HashSet<LearnerHandler>();

    // list of followers that are ready to follow (i.e synced with the leader)    
    public final HashSet<LearnerHandler> forwardingFollowers = new HashSet<LearnerHandler>();

    protected final HashSet<LearnerHandler> observingLearners = new HashSet<LearnerHandler>();

    //Pending sync requests
    public final HashMap<Long, List<LearnerSyncRequest>> pendingSyncs = new HashMap<Long, List<LearnerSyncRequest>>();

    //Follower counter
    final AtomicLong followerCounter = new AtomicLong(-1);

    /**
     * Adds peer to the leader.
     * 
     * @param learner
     *                instance of learner handle
     */
    void addLearnerHandler(LearnerHandler learner) {
        synchronized (learners) {
            learners.add(learner);
        }
    }

    /**
     * Remove the learner from the learner list
     * 
     * @param peer
     */
    void removeLearnerHandler(LearnerHandler peer) {
        synchronized (forwardingFollowers) {
            forwardingFollowers.remove(peer);
        }
        synchronized (learners) {
            learners.remove(peer);
        }
    }

    boolean isLearnerSynced(LearnerHandler peer) {
        synchronized (forwardingFollowers) {
            return forwardingFollowers.contains(peer);
        }
    }

    ServerSocket ss;

    Leader(QuorumPeer self, LeaderZooKeeperServer zk) throws IOException {
        this.self = self;
        try {
            ss = new ServerSocket(self.getQuorumAddress().getPort());
        } catch (BindException e) {
            LOG.error("Couldn't bind to port " + self.getQuorumAddress().getPort(), e);
            throw e;
        }
        this.zk = zk;
    }

    /**
     * This message is for follower to expect diff
     */
    static final int DIFF = 13;

    /**
     * This is for follower to truncate its logs 
     */
    static final int TRUNC = 14;

    /**
     * This is for follower to download the snapshots
     */
    static final int SNAP = 15;

    /**
     * This tells the leader that the connecting peer is actually an observer
     */
    static final int OBSERVERINFO = 16;

    /**
     * This message type is sent by the leader to indicate it's zxid and if
     * needed, its database.
     */
    static final int NEWLEADER = 10;

    /**
     * This message type is sent by a follower to pass the last zxid. This is here
     * for backward compatibility purposes.
     */
    static final int FOLLOWERINFO = 11;

    /**
     * This message type is sent by the leader to indicate that the follower is
     * now uptodate andt can start responding to clients.
     */
    static final int UPTODATE = 12;

    /**
     * This message is the first that a follower receives from the leader.
     * It has the protocol version and the epoch of the leader.
     */
    public static final int LEADERINFO = 17;

    /**
     * This message is used by the follow to ack a proposed epoch.
     */
    public static final int ACKEPOCH = 18;

    /**
     * This message type is sent to a leader to request and mutation operation.
     * The payload will consist of a request header followed by a request.
     */
    static final int REQUEST = 1;

    /**
     * This message type is sent by a leader to propose a mutation.
     */
    public static final int PROPOSAL = 2;

    /**
     * This message type is sent by a follower after it has synced a proposal.
     */
    static final int ACK = 3;

    /**
     * This message type is sent by a leader to commit a proposal and cause
     * followers to start serving the corresponding data.
     */
    static final int COMMIT = 4;

    /**
     * This message type is enchanged between follower and leader (initiated by
     * follower) to determine liveliness.
     */
    static final int PING = 5;

    /**
     * This message type is to validate a session that should be active.
     */
    static final int REVALIDATE = 6;

    /**
     * This message is a reply to a synchronize command flushing the pipe
     * between the leader and the follower.
     */
    static final int SYNC = 7;

    /**
     * This message type informs observers of a committed proposal.
     */
    static final int INFORM = 8;

    ConcurrentMap<Long, Proposal> outstandingProposals = new ConcurrentHashMap<Long, Proposal>();

    ConcurrentLinkedQueue<Proposal> toBeApplied = new ConcurrentLinkedQueue<Proposal>();

    Proposal newLeaderProposal = new Proposal();

    class LearnerCnxAcceptor extends Thread {

        private volatile boolean stop = false;

        @Override
        public void run() {
            try {
                while (!stop) {
                    try {
                        Socket s = ss.accept();
                        s.setSoTimeout(self.tickTime * self.syncLimit);
                        s.setTcpNoDelay(nodelay);
                        LearnerHandler fh = new LearnerHandler(s, Leader.this);
                        fh.start();
                    } catch (SocketException e) {
                        if (stop) {
                            LOG.info("exception while shutting down acceptor: " + e);
                            // When Leader.shutdown() calls ss.close(),
                            // the call to accept throws an exception.
                            // We catch and set stop to true.
                            stop = true;
                        } else {
                            throw e;
                        }
                    }
                }
            } catch (Exception e) {
                LOG.warn("Exception while accepting follower", e);
            }
        }

        public void halt() {
            stop = true;
        }
    }

    StateSummary leaderStateSummary;

    long epoch = -1;

    boolean waitingForNewEpoch = true;

    boolean readyToStart = false;

    /**
     * This method is main function that is called to lead
     * 
     * @throws IOException
     * @throws InterruptedException
     */
    void lead_dfix() throws IOException, InterruptedException, Exception {
        self.end_fle = System.currentTimeMillis();
        LOG.info("LEADING - LEADER ELECTION TOOK - " + (self.end_fle - self.start_fle));
        self.start_fle = 0;
        self.end_fle = 0;
        zk.registerJMX(new LeaderBean(this, zk), self.jmxLocalPeerBean);
        try {
            self.tick = 0;
            zk.loadData();
            leaderStateSummary = new StateSummary(self.getCurrentEpoch(), zk.getLastProcessedZxid());
            // Start thread that waits for connection requests from 
            // new followers.
            cnxAcceptor = new LearnerCnxAcceptor();
            cnxAcceptor.start();
            long epoch = getEpochToPropose(self.getId(), self.getAcceptedEpoch());
            self.setAcceptedEpoch(epoch);
            zk.setZxid(ZxidUtils.makeZxid(epoch, 0));
            synchronized (this) {
                lastProposed = zk.getZxid();
            }
            newLeaderProposal.packet = new QuorumPacket(NEWLEADER, zk.getZxid(), null, null);
            if ((newLeaderProposal.packet.getZxid() & 0xffffffffL) != 0) {
                LOG.info("NEWLEADER proposal has Zxid of " + Long.toHexString(newLeaderProposal.packet.getZxid()));
            }
            outstandingProposals.put(newLeaderProposal.packet.getZxid(), newLeaderProposal);
            readyToStart = true;
            waitForEpochAck(self.getId(), leaderStateSummary);
            self.setCurrentEpoch(epoch);
            // We have to get at least a majority of servers in sync with
            // us. We do this by waiting for the NEWLEADER packet to get
            // acknowledged
DFix_Signal(newLeaderProposal.ackSet);

            while (!self.getQuorumVerifier().containsQuorum(newLeaderProposal.ackSet)) {
                //while (newLeaderProposal.ackCount <= self.quorumPeers.size() / 2) {
                if (self.tick > self.initLimit) {
                    // Followers aren't syncing fast enough,
                    // renounce leadership!
                    StringBuilder ackToString = new StringBuilder();
                    for (Long id : newLeaderProposal.ackSet) ackToString.append(id + ": ");
                    shutdown("Waiting for a quorum of followers, only synced with: " + ackToString);
                    HashSet<Long> followerSet = new HashSet<Long>();
                    for (LearnerHandler f : learners) followerSet.add(f.getSid());
                    if (self.getQuorumVerifier().containsQuorum(followerSet)) {
                        //if (followers.size() >= self.quorumPeers.size() / 2) {
                        LOG.warn("Enough followers present. " + "Perhaps the initTicks need to be increased.");
                    }
                    return;
                }
                Thread.sleep(self.tickTime);
                self.tick++;
            }
            if (!System.getProperty("zookeeper.leaderServes", "yes").equals("no")) {
                self.cnxnFactory.setZooKeeperServer(zk);
            }
            // Everything is a go, simply start counting the ticks
            // WARNING: I couldn't find any wait statement on a synchronized
            // block that would be notified by this notifyAll() call, so
            // I commented it out
            //synchronized (this) {
            //    notifyAll();
            //}
            // We ping twice a tick, so we only update the tick every other
            // iteration
            boolean tickSkip = true;
            while (true) {
                Thread.sleep(self.tickTime / 2);
                if (!tickSkip) {
                    self.tick++;
                }
                int syncedCount = 0;
                HashSet<Long> syncedSet = new HashSet<Long>();
                // lock on the followers when we use it.
                syncedSet.add(self.getId());
                synchronized (learners) {
                    for (LearnerHandler f : learners) {
                        if (f.synced()) {
                            syncedCount++;
                            syncedSet.add(f.getSid());
                        }
                        f.ping();
                    }
                }
                if (!tickSkip && !self.getQuorumVerifier().containsQuorum(syncedSet)) {
                    //if (!tickSkip && syncedCount < self.quorumPeers.size() / 2) {
                    // Lost quorum, shutdown
                    // TODO: message is wrong unless majority quorums used
                    shutdown("Only " + syncedCount + " followers, need " + (self.getVotingView().size() / 2));
                    // the leader goes to looking
                    return;
                }
                tickSkip = !tickSkip;
            }
        } finally {
            zk.unregisterJMX(this);
        }
    }

    boolean isShutdown;

    /**
     * Close down all the LearnerHandlers
     */
    void shutdown(String reason) {
        LOG.info("Shutting down");
        if (isShutdown) {
            return;
        }
        LOG.info("Shutdown called", new Exception("shutdown Leader! reason: " + reason));
        if (cnxAcceptor != null) {
            cnxAcceptor.halt();
        }
        // NIO should not accept conenctions
        self.cnxnFactory.setZooKeeperServer(null);
        try {
            ss.close();
        } catch (IOException e) {
            LOG.warn("Ignoring unexpected exception during close", e);
        }
        // clear all the connections
        self.cnxnFactory.closeAll();
        // shutdown the previous zk
        if (zk != null) {
            zk.shutdown();
        }
        synchronized (learners) {
            for (Iterator<LearnerHandler> it = learners.iterator(); it.hasNext(); ) {
                LearnerHandler f = it.next();
                it.remove();
                f.shutdown();
            }
        }
        isShutdown = true;
    }

    /**
     * Keep a count of acks that are received by the leader for a particular
     * proposal
     * 
     * @param zxid
     *                the zxid of the proposal sent out
     * @param followerAddr
     */
    public synchronized void processAck_dfix(long sid, long zxid, SocketAddress followerAddr) throws Exception {
        boolean first = true;
        if (LOG.isTraceEnabled()) {
            LOG.trace("Ack zxid: 0x" + Long.toHexString(zxid));
            for (Proposal p : outstandingProposals.values()) {
                long packetZxid = p.packet.getZxid();
                LOG.trace("outstanding proposal: 0x" + Long.toHexString(packetZxid));
            }
            LOG.trace("outstanding proposals all");
        }
        if (outstandingProposals.size() == 0) {
            if (LOG.isDebugEnabled()) {
                LOG.debug("outstanding is 0");
            }
            return;
        }
        if (lastCommitted >= zxid) {
            if (LOG.isDebugEnabled()) {
                LOG.debug("proposal has already been committed, pzxid:" + lastCommitted + " zxid: 0x" + Long.toHexString(zxid));
            }
            // The proposal has already been committed
            return;
        }
        Proposal p = outstandingProposals.get(zxid);
        if (p == null) {
            LOG.warn("Trying to commit future proposal: zxid 0x" + Long.toHexString(zxid) + " from " + followerAddr);
            return;
        }
        p.ackSet.add(sid);
        if (LOG.isDebugEnabled()) {
            LOG.debug("Count for zxid: 0x" + Long.toHexString(zxid) + " is " + p.ackSet.size());
        }
        if (self.getQuorumVerifier().containsQuorum(p.ackSet)) {
            if (zxid != lastCommitted + 1) {
                LOG.warn("Commiting zxid 0x" + Long.toHexString(zxid) + " from " + followerAddr + " not first!");
                LOG.warn("First is " + (lastCommitted + 1));
            }
            outstandingProposals.remove(zxid);
            if (p.request != null) {
                toBeApplied.add(p);
            }
            // We don't commit the new leader proposal
            if ((zxid & 0xffffffffL) != 0) {
                if (p.request == null) {
                    LOG.warn("Going to commmit null: " + p);
                }
                commit(zxid);
                inform(p);
                zk.commitProcessor.commit(p.request);
                if (pendingSyncs.containsKey(zxid)) {
                    for (LearnerSyncRequest r : pendingSyncs.remove(zxid)) {
                        sendSync(r);
                    }
                }
                return;
            } else {
                lastCommitted = zxid;
                if (LOG.isInfoEnabled()) {
                    LOG.info("Have quorum of supporters; starting up and setting last processed zxid: " + zk.getZxid());
                }
                zk.startup();
                zk.getZKDatabase().setlastProcessedZxid(zk.getZxid());
            }
        }
    }

    static class ToBeAppliedRequestProcessor implements RequestProcessor {

        private RequestProcessor next;

        private ConcurrentLinkedQueue<Proposal> toBeApplied;

        /**
         * This request processor simply maintains the toBeApplied list. For
         * this to work next must be a FinalRequestProcessor and
         * FinalRequestProcessor.processRequest MUST process the request
         * synchronously!
         * 
         * @param next
         *                a reference to the FinalRequestProcessor
         */
        ToBeAppliedRequestProcessor(RequestProcessor next, ConcurrentLinkedQueue<Proposal> toBeApplied) {
            if (!(next instanceof FinalRequestProcessor)) {
                throw new RuntimeException(ToBeAppliedRequestProcessor.class.getName() + " must be connected to " + FinalRequestProcessor.class.getName() + " not " + next.getClass().getName());
            }
            this.toBeApplied = toBeApplied;
            this.next = next;
        }

        /*
         * (non-Javadoc)
         * 
         * @see org.apache.zookeeper.server.RequestProcessor#processRequest(org.apache.zookeeper.server.Request)
         */
        public void processRequest(Request request) {
            // request.addRQRec(">tobe");
            next.processRequest(request);
            Proposal p = toBeApplied.peek();
            if (p != null && p.request != null && p.request.zxid == request.zxid) {
                toBeApplied.remove();
            }
        }

        /*
         * (non-Javadoc)
         * 
         * @see org.apache.zookeeper.server.RequestProcessor#shutdown()
         */
        public void shutdown() {
            LOG.info("Shutting down");
            next.shutdown();
        }
    }

    /**
     * send a packet to all the followers ready to follow
     * 
     * @param qp
     *                the packet to be sent
     */
    void sendPacket(QuorumPacket qp) {
        synchronized (forwardingFollowers) {
            for (LearnerHandler f : forwardingFollowers) {
                f.queuePacket(qp);
            }
        }
    }

    /**
     * send a packet to all observers     
     */
    void sendObserverPacket(QuorumPacket qp) {
        synchronized (observingLearners) {
            for (LearnerHandler f : observingLearners) {
                f.queuePacket(qp);
            }
        }
    }

    long lastCommitted = -1;

    /**
     * Create a commit packet and send it to all the members of the quorum
     * 
     * @param zxid
     */
    public void commit(long zxid) {
        synchronized (this) {
            lastCommitted = zxid;
        }
        QuorumPacket qp = new QuorumPacket(Leader.COMMIT, zxid, null, null);
        sendPacket(qp);
    }

    /**
     * Create an inform packet and send it to all observers.
     * @param zxid
     * @param proposal
     */
    public void inform(Proposal proposal) {
        QuorumPacket qp = new QuorumPacket(Leader.INFORM, proposal.request.zxid, proposal.packet.getData(), null);
        sendObserverPacket(qp);
    }

    long lastProposed;

    /**
     * Returns the current epoch of the leader.
     * 
     * @return
     */
    public long getEpoch() {
        return ZxidUtils.getEpochFromZxid(lastProposed);
    }

    /**
     * create a proposal and send it out to all the members
     * 
     * @param request
     * @return the proposal that is queued to send to all the members
     */
    public Proposal propose(Request request) {
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        BinaryOutputArchive boa = BinaryOutputArchive.getArchive(baos);
        try {
            request.hdr.serialize(boa, "hdr");
            if (request.txn != null) {
                request.txn.serialize(boa, "txn");
            }
            baos.close();
        } catch (IOException e) {
            LOG.warn("This really should be impossible", e);
        }
        QuorumPacket pp = new QuorumPacket(Leader.PROPOSAL, request.zxid, baos.toByteArray(), null);
        Proposal p = new Proposal();
        p.packet = pp;
        p.request = request;
        synchronized (this) {
            if (LOG.isDebugEnabled()) {
                LOG.debug("Proposing:: " + request);
            }
            lastProposed = p.packet.getZxid();
            outstandingProposals.put(lastProposed, p);
            sendPacket(pp);
        }
        return p;
    }

    /**
     * Process sync requests
     * 
     * @param r the request
     */
    public synchronized void processSync(LearnerSyncRequest r) {
        if (outstandingProposals.isEmpty()) {
            sendSync(r);
        } else {
            List<LearnerSyncRequest> l = pendingSyncs.get(lastProposed);
            if (l == null) {
                l = new ArrayList<LearnerSyncRequest>();
            }
            l.add(r);
            pendingSyncs.put(lastProposed, l);
        }
    }

    /**
     * Sends a sync message to the appropriate server
     * 
     * @param f
     * @param r
     */
    public void sendSync(LearnerSyncRequest r) {
        QuorumPacket qp = new QuorumPacket(Leader.SYNC, 0, null, null);
        r.fh.queuePacket(qp);
    }

    /**
     * lets the leader know that a follower is capable of following and is done
     * syncing
     * 
     * @param handler handler of the follower
     * @return last proposed zxid
     */
    public synchronized long startForwarding(LearnerHandler handler, long lastSeenZxid) {
        // new requests
        if (lastProposed > lastSeenZxid) {
            for (Proposal p : toBeApplied) {
                if (p.packet.getZxid() <= lastSeenZxid) {
                    continue;
                }
                handler.queuePacket(p.packet);
                // Since the proposal has been committed we need to send the
                // commit message also
                QuorumPacket qp = new QuorumPacket(Leader.COMMIT, p.packet.getZxid(), null, null);
                handler.queuePacket(qp);
            }
            List<Long> zxids = new ArrayList<Long>(outstandingProposals.keySet());
            Collections.sort(zxids);
            for (Long zxid : zxids) {
                if (zxid <= lastSeenZxid) {
                    continue;
                }
                handler.queuePacket(outstandingProposals.get(zxid).packet);
            }
        }
        if (handler.getLearnerType() == LearnerType.PARTICIPANT) {
            synchronized (forwardingFollowers) {
                forwardingFollowers.add(handler);
            }
        } else {
            synchronized (observingLearners) {
                observingLearners.add(handler);
            }
        }
        return lastProposed;
    }

    private HashSet<Long> connectingFollowers = new HashSet<Long>();

    public long getEpochToPropose(long sid, long lastAcceptedEpoch) throws InterruptedException {
        synchronized (connectingFollowers) {
            if (!waitingForNewEpoch) {
                return epoch;
            }
            if (lastAcceptedEpoch > epoch) {
                epoch = lastAcceptedEpoch + 1;
            }
            connectingFollowers.add(sid);
            QuorumVerifier verifier = self.getQuorumVerifier();
            if (verifier.containsQuorum(connectingFollowers)) {
                waitingForNewEpoch = false;
                connectingFollowers.notifyAll();
            } else {
                connectingFollowers.wait(self.getInitLimit() * self.getTickTime());
                if (waitingForNewEpoch) {
                    throw new InterruptedException("Out of time to propose an epoch");
                }
            }
            return epoch;
        }
    }

    private HashSet<Long> electingFollowers = new HashSet<Long>();

    private boolean electionFinished = false;

    public void waitForEpochAck(long id, StateSummary ss) throws IOException, InterruptedException {
        synchronized (electingFollowers) {
            if (electionFinished) {
                return;
            }
            if (ss.getCurrentEpoch() != -1) {
                if (ss.isMoreRecentThan(leaderStateSummary)) {
                    throw new IOException("Follower is ahead of the leader");
                }
                electingFollowers.add(id);
            }
            QuorumVerifier verifier = self.getQuorumVerifier();
            if (readyToStart && verifier.containsQuorum(electingFollowers)) {
                electionFinished = true;
                electingFollowers.notifyAll();
            } else {
                electingFollowers.wait(self.getInitLimit() * self.getTickTime());
                if (waitingForNewEpoch) {
                    throw new InterruptedException("Out of time to propose an epoch");
                }
            }
        }
    }

    /**
     * This method is main function that is called to lead
     * 
     * @throws IOException
     * @throws InterruptedException
     */
    void lead() throws IOException, InterruptedException {
        self.end_fle = System.currentTimeMillis();
        LOG.info("LEADING - LEADER ELECTION TOOK - " + (self.end_fle - self.start_fle));
        self.start_fle = 0;
        self.end_fle = 0;
        zk.registerJMX(new LeaderBean(this, zk), self.jmxLocalPeerBean);
        try {
            self.tick = 0;
            zk.loadData();
            leaderStateSummary = new StateSummary(self.getCurrentEpoch(), zk.getLastProcessedZxid());
            // new followers.
            cnxAcceptor = new LearnerCnxAcceptor();
            cnxAcceptor.start();
            long epoch = getEpochToPropose(self.getId(), self.getAcceptedEpoch());
            self.setAcceptedEpoch(epoch);
            zk.setZxid(ZxidUtils.makeZxid(epoch, 0));
            synchronized (this) {
                lastProposed = zk.getZxid();
            }
            newLeaderProposal.packet = new QuorumPacket(NEWLEADER, zk.getZxid(), null, null);
            if ((newLeaderProposal.packet.getZxid() & 0xffffffffL) != 0) {
                LOG.info("NEWLEADER proposal has Zxid of " + Long.toHexString(newLeaderProposal.packet.getZxid()));
            }
            outstandingProposals.put(newLeaderProposal.packet.getZxid(), newLeaderProposal);
            readyToStart = true;
            waitForEpochAck(self.getId(), leaderStateSummary);
            self.setCurrentEpoch(epoch);
            // acknowledged
            newLeaderProposal.ackSet.add(self.getId());
            while (!self.getQuorumVerifier().containsQuorum(newLeaderProposal.ackSet)) {
                //while (newLeaderProposal.ackCount <= self.quorumPeers.size() / 2) {
                if (self.tick > self.initLimit) {
                    // renounce leadership!
                    StringBuilder ackToString = new StringBuilder();
                    for (Long id : newLeaderProposal.ackSet) ackToString.append(id + ": ");
                    shutdown("Waiting for a quorum of followers, only synced with: " + ackToString);
                    HashSet<Long> followerSet = new HashSet<Long>();
                    for (LearnerHandler f : learners) followerSet.add(f.getSid());
                    if (self.getQuorumVerifier().containsQuorum(followerSet)) {
                        //if (followers.size() >= self.quorumPeers.size() / 2) {
                        LOG.warn("Enough followers present. " + "Perhaps the initTicks need to be increased.");
                    }
                    return;
                }
                Thread.sleep(self.tickTime);
                self.tick++;
            }
            if (!System.getProperty("zookeeper.leaderServes", "yes").equals("no")) {
                self.cnxnFactory.setZooKeeperServer(zk);
            }
            // iteration
            boolean tickSkip = true;
            while (true) {
                Thread.sleep(self.tickTime / 2);
                if (!tickSkip) {
                    self.tick++;
                }
                int syncedCount = 0;
                HashSet<Long> syncedSet = new HashSet<Long>();
                // lock on the followers when we use it.
                syncedSet.add(self.getId());
                synchronized (learners) {
                    for (LearnerHandler f : learners) {
                        if (f.synced()) {
                            syncedCount++;
                            syncedSet.add(f.getSid());
                        }
                        f.ping();
                    }
                }
                if (!tickSkip && !self.getQuorumVerifier().containsQuorum(syncedSet)) {
                    // TODO: message is wrong unless majority quorums used
                    shutdown("Only " + syncedCount + " followers, need " + (self.getVotingView().size() / 2));
                    // the leader goes to looking
                    return;
                }
                tickSkip = !tickSkip;
            }
        } finally {
            zk.unregisterJMX(this);
        }
    }

    /**
     * Keep a count of acks that are received by the leader for a particular
     * proposal
     * 
     * @param zxid
     *                the zxid of the proposal sent out
     * @param followerAddr
     */
    public synchronized void processAck(long sid, long zxid, SocketAddress followerAddr) {
        boolean first = true;
        if (LOG.isTraceEnabled()) {
            LOG.trace("Ack zxid: 0x" + Long.toHexString(zxid));
            for (Proposal p : outstandingProposals.values()) {
                long packetZxid = p.packet.getZxid();
                LOG.trace("outstanding proposal: 0x" + Long.toHexString(packetZxid));
            }
            LOG.trace("outstanding proposals all");
        }
        if (outstandingProposals.size() == 0) {
            if (LOG.isDebugEnabled()) {
                LOG.debug("outstanding is 0");
            }
            return;
        }
        if (lastCommitted >= zxid) {
            if (LOG.isDebugEnabled()) {
                LOG.debug("proposal has already been committed, pzxid:" + lastCommitted + " zxid: 0x" + Long.toHexString(zxid));
            }
            // The proposal has already been committed
            return;
        }
        Proposal p = outstandingProposals.get(zxid);
        if (p == null) {
            LOG.warn("Trying to commit future proposal: zxid 0x" + Long.toHexString(zxid) + " from " + followerAddr);
            return;
        }
        p.ackSet.add(sid);
        if (LOG.isDebugEnabled()) {
            LOG.debug("Count for zxid: 0x" + Long.toHexString(zxid) + " is " + p.ackSet.size());
        }
        if (self.getQuorumVerifier().containsQuorum(p.ackSet)) {
            if (zxid != lastCommitted + 1) {
                LOG.warn("Commiting zxid 0x" + Long.toHexString(zxid) + " from " + followerAddr + " not first!");
                LOG.warn("First is " + (lastCommitted + 1));
            }
            outstandingProposals.remove(zxid);
            if (p.request != null) {
                toBeApplied.add(p);
            }
            // We don't commit the new leader proposal
            if ((zxid & 0xffffffffL) != 0) {
                if (p.request == null) {
                    LOG.warn("Going to commmit null: " + p);
                }
                commit(zxid);
                inform(p);
                zk.commitProcessor.commit(p.request);
                if (pendingSyncs.containsKey(zxid)) {
                    for (LearnerSyncRequest r : pendingSyncs.remove(zxid)) {
                        sendSync(r);
                    }
                }
                return;
            } else {
                lastCommitted = zxid;
                if (LOG.isInfoEnabled()) {
                    LOG.info("Have quorum of supporters; starting up and setting last processed zxid: " + zk.getZxid());
                }
                zk.startup();
                zk.getZKDatabase().setlastProcessedZxid(zk.getZxid());
            }
        }
    }

    public static HashMap<String, Semaphore> hm_dfix = new HashMap<String, Semaphore>();
}

        if (self.getQuorumVerifier().containsQuorum(p.ackSet)){             
-> DFix_Wait(p.ackSet);        if (self.getQuorumVerifier().containsQuorum(p.ackSet)){             
0 occurence use replace instead of replacefirst
No change:
    get CU to replace for QuorumPeer
                        leader.lead();
->                         leader.lead_dfix();
1 occurence use replace instead of replacefirst
ADD CLONE : ---                          leader.lead();
+++                          leader.lead_dfix();
set clone call org/apache/zookeeper/server/quorum/QuorumPeer run 729
    get AnSString to replace for LearnerHandler
            leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
->             leader.processAck_dfix(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
1 occurence use replace instead of replacefirst
ADD CLONE : ---              leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
+++              leader.processAck_dfix(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
set clone call org/apache/zookeeper/server/quorum/LearnerHandler run 411
--------  PATCH DETAILS  ---------

In the LearnerHandler.java

---              leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
+++  DFix_Repeat();

In the Leader.java

+++    public static HashMap<String, Semaphore > hm_dfix = new HashMap<String,Semaphore>();

---              newLeaderProposal.ackSet.add(self.getId());
+++  DFix_Signal(newLeaderProposal.ackSet);


---          if (self.getQuorumVerifier().containsQuorum(p.ackSet)){             
+++  DFix_Wait(p.ackSet);        if (self.getQuorumVerifier().containsQuorum(p.ackSet)){             

In the LearnerHandler.java

DFix_Repeat():
  while(true){ try{            leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());break;}catch( Exception e){}}


In the Leader.java

DFix_Signal():
String dfixkey = Integer.toString( System.identityHashCode(newLeaderProposal.ackSet));hm_dfix.put(dfixkey, new Semaphore(9999));


DFix_Wait(p.ackSet):


In the LearnerHandler.java

---              leader.processAck(this.sid, qp.getZxid(), sock.getLocalSocketAddress());
+++              leader.processAck_dfix(this.sid, qp.getZxid(), sock.getLocalSocketAddress());

In the QuorumPeer.java

---                          leader.lead();
+++                          leader.lead_dfix();

